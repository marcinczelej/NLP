{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mizzmir/NLP/blob/master/Transformer/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "160XBLnmv-sP",
    "outputId": "ebc43cec-fd14-4136-8150-ab40eac6771a"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nHsXhZrJv_cX",
    "outputId": "5bed4680-ea6e-4a18-dfab-f3364a0723f1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "\n",
    "embed_size = 10; max_steps = 3; vocab_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8_4Bkpw11pU"
   },
   "outputs": [],
   "source": [
    "class PositionalEncodingSimpleLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_dim, max_sentence_len, dtype=tf.float32, **kwargs):\n",
    "    super(PositionalEncodingSimpleLayer, self).__init__(dtype=tf.float32, **kwargs)\n",
    "    if embedding_dim %2 != 0:\n",
    "      embedding_dim+=1\n",
    "    PE = np.zeros((1, max_sentence_len, embedding_dim))\n",
    "    for pos in range(max_sentence_len):\n",
    "      for i in range(embedding_dim//2):\n",
    "        PE[:, pos, 2*i] = np.sin(pos/10000**(2*i/embedding_dim))\n",
    "        PE[:, pos, 2*i+1] = np.cos(pos/10000**(2*i/embedding_dim))\n",
    "    tf.print(PE.shape)\n",
    "    self.PE = PE\n",
    "  def call(self, input):\n",
    "    return self.PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "Ul4lfwi89x6T",
    "outputId": "29d62b34-cf3f-4d84-e446-f3a66a04b6cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 10)\n",
      "[[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "    0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "    0.00000000e+00  1.00000000e+00]\n",
      "  [ 8.41470985e-01  5.40302306e-01  1.57826640e-01  9.87466836e-01\n",
      "    2.51162229e-02  9.99684538e-01  3.98106119e-03  9.99992076e-01\n",
      "    6.30957303e-04  9.99999801e-01]\n",
      "  [ 9.09297427e-01 -4.16146837e-01  3.11697146e-01  9.50181503e-01\n",
      "    5.02165994e-02  9.98738351e-01  7.96205928e-03  9.99968302e-01\n",
      "    1.26191435e-03  9.99999204e-01]]]\n"
     ]
    }
   ],
   "source": [
    "positional_encoding_layer = PositionalEncodingSimpleLayer(embed_size, max_sentence_len=max_steps)\n",
    "res2 = positional_encoding_layer([1,2,3,4,5])\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8_EB-6u-2Hh"
   },
   "outputs": [],
   "source": [
    "class PositionalEncodingArangePos(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_size, max_sentence_len, dtype=tf.float32, **kwargs):\n",
    "    super(PositionalEncodingArangePos, self).__init__(dtype, **kwargs)\n",
    "    if embedding_size%2 !=0:\n",
    "      embedding_size+=1\n",
    "    PE = np.zeros((1, max_sentence_len, embedding_size))\n",
    "    pos = np.arange(start=0, stop=max_sentence_len, step=1)\n",
    "    for i in range(embedding_size//2):\n",
    "      PE[0, ::, 2*i] = np.sin(pos/10000**(2*i/embedding_size))\n",
    "      PE[0, ::, 2*i+1] = np.cos(pos/10000**(2*i/embedding_size))\n",
    "    self.PE = PE\n",
    "  def call(self, inputs):\n",
    "    return self.PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "Th4cZj04BZuB",
    "outputId": "d4ba58b4-3b41-4ccc-fc80-7100f9afac66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "    0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "    0.00000000e+00  1.00000000e+00]\n",
      "  [ 8.41470985e-01  5.40302306e-01  1.57826640e-01  9.87466836e-01\n",
      "    2.51162229e-02  9.99684538e-01  3.98106119e-03  9.99992076e-01\n",
      "    6.30957303e-04  9.99999801e-01]\n",
      "  [ 9.09297427e-01 -4.16146837e-01  3.11697146e-01  9.50181503e-01\n",
      "    5.02165994e-02  9.98738351e-01  7.96205928e-03  9.99968302e-01\n",
      "    1.26191435e-03  9.99999204e-01]]]\n"
     ]
    }
   ],
   "source": [
    "peLayer = PositionalEncodingArangePos(embed_size, max_sentence_len=max_steps)\n",
    "res3 = peLayer([1,2,3,4,5])\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_jeicAkABlgx",
    "outputId": "9dc5d932-d8d9-4c91-e925-495a109d5cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing arrays:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"comparing arrays: \", np.allclose(res2, res3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "s0ADeR0AGPsQ",
    "outputId": "f4765c9a-8520-4842-895c-4522e83f1f63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEncoder flow :\\n\\n- Embedding \\n- Positional Encoding\\n- Input = Embedding + Positional Encoding\\n--------------------REPEAT N Times--------------------\\n- Multi-head Attention layer\\n- Input + Multi-Head Attention layer added together \\n- previous Normalized (1)\\n- Feed Forward Network (2)\\n- (1) added to (2) and Normmalized\\n------------------------------------------------------\\n- Encoder output \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Encoder flow :\n",
    "\n",
    "- Embedding \n",
    "- Positional Encoding\n",
    "- Input = Embedding + Positional Encoding\n",
    "--------------------REPEAT N Times--------------------\n",
    "- Multi-head Attention layer\n",
    "- Input + Multi-Head Attention layer added together \n",
    "- previous Normalized (1)\n",
    "- Feed Forward Network (2)\n",
    "- (1) added to (2) and Normmalized\n",
    "------------------------------------------------------\n",
    "- Encoder output \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MI8KlrtP_ay8",
    "outputId": "92c0407a-50b9-419c-b2bd-7293146d868f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 10)\n",
      "comparing arrays:  True\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncodingLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_size, max_sentence_len, dtype=tf.float32, **kwargs):\n",
    "    super(PositionalEncodingLayer, self).__init__(dtype, **kwargs)\n",
    "    if embedding_size%2 !=0:\n",
    "      embedding_size+=1\n",
    "    # embedding size -> depth of model\n",
    "    # positional encoding should have size : [1, max_sentence_len, embedding_size]\n",
    "    # 1 is here to make broadcasting possible in call method\n",
    "    PE = np.zeros((1, max_sentence_len, embedding_size))\n",
    "    # pos should have shape [1, max_sentence_len] with values <0, max_sentence_len)\n",
    "    pos = np.arange(start=0, stop=max_sentence_len, step=1)\n",
    "    pos = pos.reshape(max_sentence_len, 1)\n",
    "    # i should have shappe [1, embedding_size//2] with values <0, embedding_size//2)\n",
    "    # we need half of embedding size, because half is needed for each sin/cos \n",
    "    # then we put it together into PE and we have [1, max_sentence_len, embedding_size]\n",
    "    i = np.arange(start=0, stop=embedding_size//2, step=1)\n",
    "    i = i.reshape(embedding_size//2, 1).T\n",
    "    PE_sin = np.sin(pos/10000**(2*i/embedding_size))\n",
    "    PE_cos = np.cos(pos/10000**(2*i/embedding_size))\n",
    "    # we put sin into even indexes ::2 \n",
    "    # we put cos into odd indexes, thats why we`re starting from 1 here : 1::2\n",
    "    PE[0, ::, ::2] = PE_sin\n",
    "    PE[0, ::, 1::2] = PE_cos\n",
    "    self.PE = tf.constant(PE, dtype=dtype)\n",
    "  def getPE(self):\n",
    "    \"\"\"\n",
    "    only for debuging purposes\n",
    "    \"\"\"\n",
    "    return self.PE\n",
    "  def call(self, inputs):\n",
    "    \"\"\"\n",
    "    inputs shape should be same as self.PE shape\n",
    "        \n",
    "      input_shape = tf.shape(inputs)\n",
    "      return inputs + self.PE[:, :input_shape[-2], :]\n",
    "\n",
    "    It has to be that way becuase we need to be able to get positional encoding for different lenght \n",
    "    for encoder and decoder, when we don`t know max lenght. SO we have to do encoding with bigger buffer\n",
    "    and take what we need only.\n",
    "\n",
    "    max_sentence_len in should be bigger or equal as longest input we predict we can get\n",
    "    \"\"\"\n",
    "\n",
    "    input_shape = tf.shape(inputs)\n",
    "    return inputs + self.PE[:, :input_shape[-2], :]\n",
    "\n",
    "peLayerAll = PositionalEncodingLayer(embedding_size=10,\n",
    "                                     max_sentence_len=max_steps)\n",
    "res4 = peLayerAll.getPE()\n",
    "print(res4.shape)\n",
    "print(\"comparing arrays: \", np.allclose(res2, res4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqxOYEMvhs4n"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_size, heads_number, dtype=tf.float32, **kwargs):\n",
    "    super(MultiHeadAttentionLayer, self).__init__(dtype=tf.float32, **kwargs)\n",
    "    \"\"\"\n",
    "    return shape : [batch_size, sequence_len, d_model]\n",
    "    heads_number - tell how many heads will be processed at same time\n",
    "    d_model - model size ; equal to embedding_size\n",
    "    \"\"\"\n",
    "    self.heads_number = heads_number\n",
    "    self.d_model = embedding_size\n",
    "    self.w_q = tf.keras.layers.Dense(self.d_model)\n",
    "    self.w_k = tf.keras.layers.Dense(self.d_model)\n",
    "    self.w_v = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "    self.outputLayer = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "  # similar to dot attention but with scaling added\n",
    "  def ScaledDotProductAttention(self, v, k, q, sequence_mask):\n",
    "    \"\"\"\n",
    "    q shape [batch_size, num_heads, q_seq_len, depth_q]\n",
    "    k shape [batch_size, num_heads, k_seq_len, depth_k]\n",
    "    v shape [batch_size, num_heads, v_seq_len, depth_v]\n",
    "    \"\"\"\n",
    "    # matmul(q,k,v)\n",
    "    # resultion shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
    "    qk_matmul = tf.matmul(q, k, transpose_b=True)\n",
    "    # scaling tf.cast is needed here because tf.sqrt needs float32 type\n",
    "    # score shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
    "    score = qk_matmul*tf.math.sqrt(tf.cast(k.shape[-1], dtype=tf.float32))\n",
    "    # optional mask\n",
    "    # mask should be shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
    "    # for example [\n",
    "    #             [0, 1, 1]\n",
    "    #             [0, 0, 1]\n",
    "    #             ] shape == (2, 3)\n",
    "    # we`re adding big negative number, because we only care about present/past words that are przedicted\n",
    "    if sequence_mask is not None:\n",
    "      #print(\" mask is not none\")\n",
    "      #print(\"sequence_mask shape {}\\nscore shape {}\" .format(sequence_mask.shape, score.shape))\n",
    "      score += sequence_mask*-1e-8\n",
    "    # softmax\n",
    "    # attention_weights shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
    "    attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "    # matmul(res, V)\n",
    "    # contex shape [batch_size, num_heads, q_seq_len, depth_v]\n",
    "    context = tf.matmul(attention_weights, v)\n",
    "    return context\n",
    "\n",
    "  def splitHeads(self, data):\n",
    "    # new shape [batch_size, sequence_len, heads_number, d_model//heads_number]\n",
    "    data = tf.reshape(data, (data.shape[0], data.shape[1], self.heads_number, data.shape[-1]//self.heads_number))\n",
    "    # transpose dimentions to [batch_size, heads_number, sequence_len, d_model//heads_number]\n",
    "    return tf.transpose(data, perm=[0,2,1,3])\n",
    "\n",
    "  def call(self, q, k, v, sequence_mask):\n",
    "    \"\"\"\n",
    "    q shape [batch_size, sequence_len, d_model]\n",
    "    k shape [batch_size, sequence_len, d_model]\n",
    "    v shape [batch_size, sequence_len, d_model]\n",
    "\n",
    "    after first operations shapes are the same\n",
    "    next we have to split d_model into heads_number of subbatches\n",
    "    new shape after reshape only should be : [batch_size, sequence_len, heads_number, d_model//heads_number]\n",
    "    next shape should be transposed to : [batch_size, heads_number, sequence_len, d_model//heads_number]\n",
    "    where :\n",
    "      new_d_model = d_model/heads_number\n",
    "    \n",
    "    next make scaled dot-product attention on resulting q,k,v\n",
    "\n",
    "    next concat returning data to get shape : [batch_size, sequence_len, d_model]\n",
    "    in order to do this we have to transpose context_vector to get [batch_size, sequence_len, heads_number, d_model//heads_number]\n",
    "\n",
    "    next put it throug dense layer (d_model) in order to get output\n",
    "    \"\"\"\n",
    "    #print(\"q shape {}\\nk shape {}\\n v shape {}\" .format(q.shape, k.shape, v.shape))\n",
    "    q = self.w_q(q)\n",
    "    k = self.w_k(k)\n",
    "    v = self.w_v(v)\n",
    "    #print(\"AFTER Dense\\n  q shape {}\\n  k shape {}\\n  v shape {}\" .format(q.shape, k.shape, v.shape))\n",
    "\n",
    "    q = self.splitHeads(q)\n",
    "    k = self.splitHeads(k)\n",
    "    v = self.splitHeads(v)\n",
    "    #print(\"AFTER SPLIT\\n  q shape {}\\n  k shape {}\\n  v shape {}\" .format(q.shape, k.shape, v.shape))\n",
    "\n",
    "    context_vector = self.ScaledDotProductAttention(q, k, v, sequence_mask)\n",
    "    #print(\"context_vector shape :\", context_vector.shape)\n",
    "\n",
    "    context_vector = tf.transpose(context_vector, perm=[0,2,1,3])\n",
    "    #print(\"context_vector  transposed shape :\", context_vector.shape)\n",
    "    context_vector = tf.reshape(context_vector, (context_vector.shape[0], context_vector.shape[1], self.d_model))\n",
    "    #print(\"context_vector  reshapeed shape :\", context_vector.shape)\n",
    "\n",
    "    return self.outputLayer(context_vector)\n",
    "\n",
    "embed_size = 10; max_steps = 3; vocab_size = 100\n",
    "\n",
    "q = tf.random.uniform((1, max_steps, embed_size))  # shape [batch_size, sequence_len, embedding_size]\n",
    "mhatt = MultiHeadAttentionLayer(embed_size, 5)\n",
    "mhatt_output = mhatt(q, k=q, v=q, sequence_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4GNTftVHb5x"
   },
   "outputs": [],
   "source": [
    "def feedForwardnetwork(dff, d_model):\n",
    "  \"\"\"\n",
    "  according to paper dff=2048 and d_model =512\n",
    "  but d_model should be same as embedding_size/d_model in MultiHeadAttention\n",
    "  ffn(x) = max(0, xW_1 + b+1)W_2 + b_2\n",
    "  where max(0, ...) -> relu activation\n",
    "  \"\"\"\n",
    "  ffNetwork = tf.keras.Sequential()\n",
    "  ffNetwork.add(tf.keras.layers.Dense(dff, activation=\"relu\"))\n",
    "  ffNetwork.add(tf.keras.layers.Dense(d_model))\n",
    "  return ffNetwork\n",
    "\n",
    "def makeSequenceMask(seq_len):\n",
    "  \"\"\"\n",
    "  mask should be size [1, 1, seq_len, seq_len]\n",
    "  first two sizes are batch_szie, num_heads to make this matrix broadcastable\n",
    "  it should be in form \n",
    "  [\n",
    "    [0, 1, 1, 1]\n",
    "    [0, 0, 1, 1]\n",
    "    [0, 0, 0, 1]\n",
    "    [0, 0, 0, 0]\n",
    "  ]\n",
    "  \"\"\"\n",
    "  mask_array = np.ones((seq_len, seq_len))\n",
    "  mask_array = np.triu(mask_array, 1)\n",
    "  return tf.constant(mask_array, dtype=tf.float32)\n",
    "\n",
    "def makePaddingMask(sequence):\n",
    "  mask = tf.math.equal(sequence, 0)\n",
    "  mask =  tf.cast(mask, tf.float32)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-_p_e0UNCpG"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_size, heads_number, dff, dtype=tf.float32, **kwargs):\n",
    "    super(EncoderLayer, self).__init__(dtype, **kwargs)\n",
    "\n",
    "    self.d_model = embedding_size\n",
    "    self.multiHeadAttention = MultiHeadAttentionLayer(embedding_size, heads_number)\n",
    "\n",
    "    self.normalizationFirst = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.normalizationSecond = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.ffNetwork = feedForwardnetwork(dff, self.d_model)\n",
    "\n",
    "  def call(self, encoder_input, mask):\n",
    "    # shortcut_data shape [batch_szie, max_sentence_len, embedding_size]\n",
    "    shortcut_data = encoder_input\n",
    "\n",
    "    # mhatt_output shape [batch_size, max_sentence_len, embedding_size]\n",
    "    mhatt_output = self.multiHeadAttention(encoder_input, encoder_input, encoder_input, mask)\n",
    "    mhatt_output += shortcut_data\n",
    "    mhatt_output = self.normalizationFirst(mhatt_output)\n",
    "\n",
    "    shortcut_data = mhatt_output\n",
    "\n",
    "    ffNet_output = self.ffNetwork(mhatt_output)\n",
    "    ffNet_output += shortcut_data\n",
    "    ffNet_output = self.normalizationSecond(ffNet_output)\n",
    "\n",
    "    return ffNet_output\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, embedding_size, max_sentence_len, vocab_size, blocks_amount, heads_number, dff):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    assert (embedding_size//heads_number)%2==0\n",
    "    self.blocks_amount = blocks_amount\n",
    "    self.d_model = embedding_size\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "    self.positionalEncoding = PositionalEncodingLayer(embedding_size, max_sentence_len)\n",
    "\n",
    "    self.encoderBlocks = [EncoderLayer(embedding_size, heads_number, dff) for _ in range(blocks_amount)]\n",
    "  \n",
    "  def call(self, encoder_input, mask):\n",
    "    # sequence shape [batch_size, max_sentence_len]\n",
    "    embedded_seq = self.embedding(encoder_input)\n",
    "    # according to paper https://arxiv.org/pdf/1706.03762.pdf\n",
    "    # embedding is multiplied by sqrt(d_model). Point 3.4\n",
    "    embedded_seq*=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    # embedded_seq shape [batch_szie, max_sentence_len, embedding_size]\n",
    "    data = self.positionalEncoding(embedded_seq)\n",
    "    #------------------------- loop though all blocks -------------------------\n",
    "    for i in range(self.blocks_amount):\n",
    "      #print(\"               BLOCK \", i+1)\n",
    "      data = self.encoderBlocks[i](data, mask) \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "8T85ncKrVRYC",
    "outputId": "f3bc520e-a810-4351-bded-f8cefa0d4e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape  (32, 3)\n",
      "WARNING:tensorflow:Layer encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(32, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.ones((32, max_steps))\n",
    "print(\"input shape \", data.shape)\n",
    "padding_mask = makePaddingMask(data)\n",
    "\n",
    "encoder = Encoder(embedding_size=10,\n",
    "                  max_sentence_len=1000,\n",
    "                  vocab_size=100,\n",
    "                  blocks_amount=3,\n",
    "                  heads_number=5, \n",
    "                  dff=2048)\n",
    "encoder_out  = encoder(data, mask=padding_mask)\n",
    "print(encoder_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YhbwxVGBVwzP",
    "outputId": "4f51058c-3404-4db6-c1b2-ef03f3a6382f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDecoder flow :\\n\\n- Embedding \\n- Positional Encoding\\n- Input = Embedding + Positional Encoding\\n--------------------REPEAT N Times--------------------\\n- Masked Multi-head Attention layer\\n- Input + Masked Multi-Head Attention layer added together \\n- previous Normalized (1) \\n- Multi-head Attention layer v, k from Encoder output | q from previous point\\n- (1) + Multi-head Attention layer added together\\n- previous normalized\\n- Feed Forward Network (2)\\n- (1) added to (2) and Normalized\\n------------------------------------------------------\\n- Decoder output\\n- Linear layer\\n- softmax\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Decoder flow :\n",
    "\n",
    "- Embedding \n",
    "- Positional Encoding\n",
    "- Input = Embedding + Positional Encoding\n",
    "--------------------REPEAT N Times--------------------\n",
    "- Masked Multi-head Attention layer\n",
    "- Input + Masked Multi-Head Attention layer added together \n",
    "- previous Normalized (1) \n",
    "- Multi-head Attention layer v, k from Encoder output | q from previous point\n",
    "- (1) + Multi-head Attention layer added together\n",
    "- previous normalized\n",
    "- Feed Forward Network (2)\n",
    "- (1) added to (2) and Normalized\n",
    "------------------------------------------------------\n",
    "- Decoder output\n",
    "- Linear layer\n",
    "- softmax\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrE1qDbL3i0G"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_size, heads_number, dff, dtype=tf.float32, **kwargs):\n",
    "    super(DecoderLayer, self).__init__(dtype, **kwargs)\n",
    "\n",
    "    self.d_model = embedding_size\n",
    "    self.multiHeadAttentionFirst = MultiHeadAttentionLayer(embedding_size, heads_number)\n",
    "    self.multiHeadAttentionSecond = MultiHeadAttentionLayer(embedding_size, heads_number)\n",
    "\n",
    "    self.normalizationFirst = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.normalizationSecond = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.normalizationThird = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.ffNetwork = feedForwardnetwork(dff, self.d_model)\n",
    "\n",
    "  def call(self, decoder_input, encoder_output, pad_mask, elements_mask):\n",
    "    # shortcut_data shape [batch_szie, max_sentence_len, embedding_size]\n",
    "    shortcut_data = decoder_input\n",
    "      \n",
    "    # mhatt_output shape [batch_size, max_sentence_len, embedding_size]\n",
    "    mhatt_output = self.multiHeadAttentionFirst(decoder_input, decoder_input, decoder_input, elements_mask)\n",
    "    # add & Norm\n",
    "    mhatt_output += shortcut_data\n",
    "    mhatt_output = self.normalizationFirst(mhatt_output)\n",
    "\n",
    "    shortcut_data = mhatt_output\n",
    "    mhatt_output = self.multiHeadAttentionSecond(encoder_output, encoder_output, mhatt_output, pad_mask)\n",
    "    mhatt_output += shortcut_data\n",
    "    mhatt_output = self.normalizationSecond(mhatt_output)\n",
    "\n",
    "    shortcut_data = mhatt_output\n",
    "    ffn_output = self.ffNetwork(mhatt_output)\n",
    "    ffn_output += shortcut_data\n",
    "    ffNet_output = self.normalizationThird(ffn_output)\n",
    "\n",
    "    return ffNet_output\n",
    "\n",
    "class Decoder(tf.keras.models.Model):\n",
    "  def __init__(self, embedding_size, max_sentence_len, vocab_size, blocks_amount, heads_number, dff):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    assert (embedding_size//heads_number)%2==0\n",
    "    self.blocks_amount = blocks_amount\n",
    "    self.d_model = embedding_size\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "    self.positionalEncoding = PositionalEncodingLayer(embedding_size, max_sentence_len)\n",
    "\n",
    "    self.decoderBlocks = [DecoderLayer(embedding_size, heads_number, dff) for _ in range(blocks_amount)]\n",
    "\n",
    "  def call(self, encoder_output, decoder_input, pad_mask, elements_mask):\n",
    "\n",
    "    # sequence shape [batch_size, max_sentence_len]\n",
    "    embedded_seq = self.embedding(decoder_input)\n",
    "    # according to paper https://arxiv.org/pdf/1706.03762.pdf\n",
    "    # embedding is multiplied by sqrt(d_model). Point 3.4\n",
    "    embedded_seq*=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    # embedded_seq shape [batch_szie, max_sentence_len, embedding_size]\n",
    "    data = self.positionalEncoding(embedded_seq)\n",
    "    #------------------------- loop though all blocks -------------------------\n",
    "    for i in range(self.blocks_amount):\n",
    "      #print(\"               BLOCK \", i+1)\n",
    "      data = self.decoderBlocks[i](data, encoder_output, pad_mask, elements_mask)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "F8Wb0q1bvlxa",
    "outputId": "bb09769a-a96c-47de-f398-e25bb59b048a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder input shape  (32, 3)\n",
      "decoder_out  (32, 15, 10)\n"
     ]
    }
   ],
   "source": [
    "input_data = np.ones((32, max_steps))\n",
    "output_data = tf.random.uniform((32, 15))\n",
    "mask = makeSequenceMask(output_data.shape[1])\n",
    "print(\"Decoder input shape \", data.shape)\n",
    "blocks_amount = 2\n",
    "heads = 5\n",
    "en_vocab_size = 100\n",
    "fr_vocab_size = 200\n",
    "decoder = Decoder(embedding_size=10,\n",
    "                  max_sentence_len=1000,\n",
    "                  vocab_size=100,\n",
    "                  blocks_amount=3,\n",
    "                  heads_number=5, \n",
    "                  dff=2048)\n",
    "\"\"\"\n",
    "decoder masks are :\n",
    "- encoder_padding_mask\n",
    "- decoder sequences mask\n",
    "\"\"\"\n",
    "decoder_out  = decoder(encoder_out, output_data, pad_mask=padding_mask, elements_mask=mask)\n",
    "print(\"decoder_out \", decoder_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xM03dp3qwO_9"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.models.Model):\n",
    "  def __init__(self,\n",
    "               embedding_size,\n",
    "               dff,\n",
    "               input_max_seq_length,\n",
    "               output_max_seq_length,\n",
    "               input_vocab_size,\n",
    "               output_vocab_size,\n",
    "               encoder_blocks,\n",
    "               decoder_blocks,\n",
    "               heads):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(embedding_size, input_max_seq_length, input_vocab_size, encoder_blocks, heads, dff)\n",
    "    self.decoder = Decoder(embedding_size, output_max_seq_length, output_vocab_size, decoder_blocks, heads, dff)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(output_vocab_size)\n",
    "\n",
    "  def call(self, input_seq, output_seq, pad_mask, words_mask):\n",
    "    \n",
    "    encoder_out = self.encoder(input_seq, mask=pad_mask)\n",
    "    decoder_out = self.decoder(encoder_out, output_seq, pad_mask=pad_mask, elements_mask=words_mask)\n",
    "\n",
    "    # transformer_out shape = [batch_size, ]\n",
    "    transformer_out = self.dense(decoder_out)\n",
    "    return transformer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "mrJPalvR37Xp",
    "outputId": "39dc0019-d95c-4f91-fc83-25d2c7ef73b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_data  (64, 29)\n",
      "elements_mask  (29, 29)\n",
      "(64, 29, 7001)\n"
     ]
    }
   ],
   "source": [
    "transformer_model = Transformer(embedding_size=512,\n",
    "                                dff=2048,\n",
    "                                input_max_seq_length=2000,\n",
    "                                output_max_seq_length=1855,\n",
    "                                input_vocab_size=4980,\n",
    "                                output_vocab_size=7001,\n",
    "                                encoder_blocks=4,\n",
    "                                decoder_blocks=2,\n",
    "                                heads=8)\n",
    "\n",
    "# input_data and output_data\n",
    "input_data = tf.random.uniform((64, 52), dtype=tf.int64, minval=0, maxval=100)\n",
    "output_data = tf.random.uniform((64, 29), dtype=tf.int64, minval=0, maxval=250)\n",
    "\n",
    "encoder_pad_mask = makePaddingMask(input_data)\n",
    "elements_mask = makeSequenceMask(output_data.shape[1])\n",
    "print(\"output_data \", output_data.shape)\n",
    "print(\"elements_mask \", elements_mask.shape)\n",
    "transformer_output = transformer_model(input_data, output_data, encoder_pad_mask, elements_mask)\n",
    "print(transformer_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6QCBpOj4OAW"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "according to Attention is all you need paper learning rate has custom scheduler:\n",
    "there are two parameters : \n",
    "- d_model\n",
    "- warmup_steps ( in paper set to 4000)\n",
    "\"\"\"\n",
    "class customLearningRate(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, warmup_steps, d_model):\n",
    "    super(customLearningRate, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.warmup_steps = warmup_steps\n",
    "  \n",
    "  def __call__(self, step):\n",
    "    firstScheduler = step**(-0.5)\n",
    "    secondScheduler = step*self.warmup_steps**(-0.5)\n",
    "    return self.d_model**(-0.5)*tf.minimum(firstScheduler, secondScheduler)\n",
    "\n",
    "custom_learning_rate = customLearningRate(warmup_steps=4000,\n",
    "                                          d_model=512)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=custom_learning_rate,\n",
    "                                    beta_1=0.9,\n",
    "                                    beta_2=0.98,\n",
    "                                    epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgYd2QMDr__v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bq1qufXuXYqW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from  data/small_vocab_en\n",
      "reading data from  data/small_vocab_fr\n"
     ]
    }
   ],
   "source": [
    "# reading data\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "en_lines, fr_lines = read_data_files(\"data\", (\"small_vocab_en\", \"small_vocab_fr\"))\n",
    "\n",
    "#data = read_data(\"data/fra-eng\", \"fra.txt\")\n",
    "#en_lines, fr_lines = list(zip(*data))\n",
    "\n",
    "en_lines = [normalize(line) for line in en_lines]\n",
    "fr_lines = [normalize(line) for line in fr_lines]\n",
    "\n",
    "en_train, en_test, fr_train, fr_test = train_test_split(en_lines, fr_lines, shuffle=True, test_size=0.1)\n",
    "\n",
    "fr_train_in = ['<start> ' + line for line in fr_train]\n",
    "fr_train_out = [line + ' <end>' for line in fr_train]\n",
    "\n",
    "fr_test_in = ['<start> ' + line for line in fr_test]\n",
    "fr_test_out = [line + ' <end>' for line in fr_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab 203\n",
      "fr_vocab 336\n"
     ]
    }
   ],
   "source": [
    "fr_tokenizer = Tokenizer(filters='')\n",
    "en_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "input_data = [fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train]\n",
    "fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train = tokenizeInput(input_data, fr_tokenizer)\n",
    "\n",
    "input_data = [en_train, en_test]\n",
    "en_train, en_test = tokenizeInput(input_data, en_tokenizer)\n",
    "\n",
    "en_vocab_size = len(en_tokenizer.word_index)+1\n",
    "fr_vocab_size = len(fr_tokenizer.word_index)+1\n",
    "print(\"en_vocab {}\\nfr_vocab {}\" .format(en_vocab_size, fr_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((en_train, fr_train_in, fr_train_out))\n",
    "train_dataset = train_dataset.shuffle(len(en_train), reshuffle_each_iteration=True)\\\n",
    "                                 .batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((en_test, fr_test_in, fr_test_out))\n",
    "test_dataset = test_dataset.shuffle(len(en_test), reshuffle_each_iteration=True)\\\n",
    "                               .batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches per epoch : 1938\n"
     ]
    }
   ],
   "source": [
    "print(\"Training batches per epoch :\", len(en_train)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training Loss 2.6365 Accuracy 0.0618  test Loss 2.8668 Accuracy 0.0677\n",
      "Epoch 2 training Loss 2.6214 Accuracy 0.0621  test Loss 2.8657 Accuracy 0.0678\n",
      "Epoch 3 training Loss 2.6207 Accuracy 0.0621  test Loss 2.8653 Accuracy 0.0678\n",
      "Epoch 4 training Loss 2.6204 Accuracy 0.0621  test Loss 2.8651 Accuracy 0.0678\n",
      "Epoch 5 training Loss 2.6203 Accuracy 0.0621  test Loss 2.8651 Accuracy 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-24-2b8d4754ac5b>\", line 61, in <module>\n",
      "    train_step(en_data, fr_data_in, fr_train_out)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 487, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1823, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1141, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 185, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/usr/lib/python3.6/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/lib/python3.6/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/usr/lib/python3.6/codecs.py\", line 318, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "transformer_model = Transformer(embedding_size=512,\n",
    "                                dff=1024,\n",
    "                                input_max_seq_length=2000,\n",
    "                                output_max_seq_length=1855,\n",
    "                                input_vocab_size=en_vocab_size,\n",
    "                                output_vocab_size=fr_vocab_size,\n",
    "                                encoder_blocks=3,\n",
    "                                decoder_blocks=3,\n",
    "                                heads=8)\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "training_loss = tf.keras.metrics.Mean()\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True)\n",
    "\n",
    "def loss_fn(real, targets):\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, tf.int64)\n",
    "    loss = loss_object(targets, real, sample_weight=mask)\n",
    "    return tf.reduce_mean(loss)    \n",
    "\n",
    "@tf.function\n",
    "def train_step(input_data, real_data_in, real_data_out):\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_pad_mask = makePaddingMask(input_data)\n",
    "        elements_mask = makeSequenceMask(real_data_in.shape[1])\n",
    "        predicted_data = transformer_model(input_data, real_data_in, encoder_pad_mask, elements_mask)\n",
    "        \n",
    "        loss = loss_fn(predicted_data, real_data_out)\n",
    "  \n",
    "    trainable_vars = transformer_model.trainable_variables\n",
    "    grads = tape.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(grads, trainable_vars))\n",
    "    train_accuracy(real_data_out, predicted_data)\n",
    "    training_loss(loss)\n",
    "\n",
    "@tf.function\n",
    "def test_step(input_data, real_data_in, real_data_out):\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_pad_mask = makePaddingMask(input_data)\n",
    "        elements_mask = makeSequenceMask(real_data_in.shape[1])\n",
    "        predicted_data = transformer_model(input_data, real_data_in, encoder_pad_mask, elements_mask, training=False)\n",
    "        \n",
    "        loss = loss_fn(predicted_data, real_data_out)\n",
    "  \n",
    "    test_accuracy(real_data_out, predicted_data)\n",
    "    test_loss(loss)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    training_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for batch, (en_data, fr_data_in, fr_train_out) in enumerate(train_dataset):\n",
    "        train_step(en_data, fr_data_in, fr_train_out)\n",
    "    for _, (en_data, fr_data_in, fr_data_out) in enumerate(test_dataset):\n",
    "        test_step(en_data, fr_data_in, fr_data_out)\n",
    "        \n",
    "    print ('Epoch {} training Loss {:.4f} Accuracy {:.4f}  test Loss {:.4f} Accuracy {:.4f}' .format( \\\n",
    "                                                epoch + 1, \n",
    "                                                training_loss.result(), \n",
    "                                                train_accuracy.result(),\n",
    "                                                test_loss.result(),\n",
    "                                                test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
