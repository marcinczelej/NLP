{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mizzmir/NLP/blob/master/Transformer/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "160XBLnmv-sP",
        "outputId": "0ae83063-cc0b-4190-b2d7-fd4c419f1834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "!pip install tensorflow-gpu\n",
        "!git clone https://github.com/mizzmir/NLP.git\n",
        "collab = True"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.0.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
            "fatal: destination path 'NLP' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nHsXhZrJv_cX",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "if collab:\n",
        "  sys.path.insert(0, r\"./NLP/utilities\")\n",
        "  data_dir = \"./NLP/data\"\n",
        "else:\n",
        "  sys.path.insert(0, r\"../utilities\")\n",
        "  data_dir = \"../data\"\n",
        "\n",
        "from utils import *\n",
        "\n",
        "embed_size = 10; max_steps = 3; vocab_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j8_4Bkpw11pU",
        "colab": {}
      },
      "source": [
        "class PositionalEncodingSimpleLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_dim, max_sentence_len, dtype=tf.float32, **kwargs):\n",
        "    super(PositionalEncodingSimpleLayer, self).__init__(dtype=tf.float32, **kwargs)\n",
        "    if embedding_dim %2 != 0:\n",
        "      embedding_dim+=1\n",
        "    PE = np.zeros((1, max_sentence_len, embedding_dim))\n",
        "    for pos in range(max_sentence_len):\n",
        "      for i in range(embedding_dim//2):\n",
        "        PE[:, pos, 2*i] = np.sin(pos/10000**(2*i/embedding_dim))\n",
        "        PE[:, pos, 2*i+1] = np.cos(pos/10000**(2*i/embedding_dim))\n",
        "    tf.print(PE.shape)\n",
        "    self.PE = PE\n",
        "  def call(self, input):\n",
        "    return self.PE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ul4lfwi89x6T",
        "outputId": "68b85354-aa0a-4b75-d995-259cda8f381b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "positional_encoding_layer = PositionalEncodingSimpleLayer(embed_size, max_sentence_len=max_steps)\n",
        "res2 = positional_encoding_layer([1,2,3,4,5])\n",
        "print(res2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 10)\n",
            "[[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "    0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "    0.00000000e+00  1.00000000e+00]\n",
            "  [ 8.41470985e-01  5.40302306e-01  1.57826640e-01  9.87466836e-01\n",
            "    2.51162229e-02  9.99684538e-01  3.98106119e-03  9.99992076e-01\n",
            "    6.30957303e-04  9.99999801e-01]\n",
            "  [ 9.09297427e-01 -4.16146837e-01  3.11697146e-01  9.50181503e-01\n",
            "    5.02165994e-02  9.98738351e-01  7.96205928e-03  9.99968302e-01\n",
            "    1.26191435e-03  9.99999204e-01]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-8_EB-6u-2Hh",
        "colab": {}
      },
      "source": [
        "class PositionalEncodingArangePos(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_size, max_sentence_len, dtype=tf.float32, **kwargs):\n",
        "    super(PositionalEncodingArangePos, self).__init__(dtype, **kwargs)\n",
        "    if embedding_size%2 !=0:\n",
        "      embedding_size+=1\n",
        "    PE = np.zeros((1, max_sentence_len, embedding_size))\n",
        "    pos = np.arange(start=0, stop=max_sentence_len, step=1)\n",
        "    for i in range(embedding_size//2):\n",
        "      PE[0, ::, 2*i] = np.sin(pos/10000**(2*i/embedding_size))\n",
        "      PE[0, ::, 2*i+1] = np.cos(pos/10000**(2*i/embedding_size))\n",
        "    self.PE = PE\n",
        "  def call(self, inputs):\n",
        "    return self.PE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Th4cZj04BZuB",
        "outputId": "74485322-48b9-436c-c04f-271f91c78a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "peLayer = PositionalEncodingArangePos(embed_size, max_sentence_len=max_steps)\n",
        "res3 = peLayer([1,2,3,4,5])\n",
        "print(res3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "    0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
            "    0.00000000e+00  1.00000000e+00]\n",
            "  [ 8.41470985e-01  5.40302306e-01  1.57826640e-01  9.87466836e-01\n",
            "    2.51162229e-02  9.99684538e-01  3.98106119e-03  9.99992076e-01\n",
            "    6.30957303e-04  9.99999801e-01]\n",
            "  [ 9.09297427e-01 -4.16146837e-01  3.11697146e-01  9.50181503e-01\n",
            "    5.02165994e-02  9.98738351e-01  7.96205928e-03  9.99968302e-01\n",
            "    1.26191435e-03  9.99999204e-01]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jeicAkABlgx",
        "outputId": "238af4ec-5343-4cbb-f624-1f68eec8654f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"comparing arrays: \", np.allclose(res2, res3))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comparing arrays:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s0ADeR0AGPsQ",
        "outputId": "5da63bc5-6410-48a9-c0a8-c1ee1f57945f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "Encoder flow :\n",
        "\n",
        "- Embedding \n",
        "- Positional Encoding\n",
        "- Input = Embedding + Positional Encoding\n",
        "--------------------REPEAT N Times--------------------\n",
        "- Multi-head Attention layer\n",
        "- Input + Multi-Head Attention layer added together \n",
        "- previous Normalized (1)\n",
        "- Feed Forward Network (2)\n",
        "- (1) added to (2) and Normmalized\n",
        "------------------------------------------------------\n",
        "- Encoder output \n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nEncoder flow :\\n\\n- Embedding \\n- Positional Encoding\\n- Input = Embedding + Positional Encoding\\n--------------------REPEAT N Times--------------------\\n- Multi-head Attention layer\\n- Input + Multi-Head Attention layer added together \\n- previous Normalized (1)\\n- Feed Forward Network (2)\\n- (1) added to (2) and Normmalized\\n------------------------------------------------------\\n- Encoder output \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MI8KlrtP_ay8",
        "colab": {}
      },
      "source": [
        "class PositionalEncodingLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_size, max_sentence_len, dtype=tf.float32, **kwargs):\n",
        "    super(PositionalEncodingLayer, self).__init__(dtype, **kwargs)\n",
        "    if embedding_size%2 !=0:\n",
        "      embedding_size+=1\n",
        "    # embedding size -> depth of model\n",
        "    # positional encoding should have size : [1, max_sentence_len, embedding_size]\n",
        "    # 1 is here to make broadcasting possible in call method\n",
        "    PE = np.zeros((1, max_sentence_len, embedding_size))\n",
        "    # pos should have shape [1, max_sentence_len] with values <0, max_sentence_len)\n",
        "    pos = np.arange(start=0, stop=max_sentence_len, step=1)\n",
        "    pos = pos.reshape(max_sentence_len, 1)\n",
        "    # i should have shappe [1, embedding_size//2] with values <0, embedding_size//2)\n",
        "    # we need half of embedding size, because half is needed for each sin/cos \n",
        "    # then we put it together into PE and we have [1, max_sentence_len, embedding_size]\n",
        "    i = np.arange(start=0, stop=embedding_size//2, step=1)\n",
        "    i = i.reshape(embedding_size//2, 1).T\n",
        "    PE_sin = np.sin(pos/10000**(2*i/embedding_size))\n",
        "    PE_cos = np.cos(pos/10000**(2*i/embedding_size))\n",
        "    # we put sin into even indexes ::2 \n",
        "    # we put cos into odd indexes, thats why we`re starting from 1 here : 1::2\n",
        "    PE[0, ::, ::2] = PE_sin\n",
        "    PE[0, ::, 1::2] = PE_cos\n",
        "    self.PE = tf.constant(PE, dtype=dtype)\n",
        "  def getPE(self):\n",
        "    \"\"\"\n",
        "    only for debuging purposes\n",
        "    \"\"\"\n",
        "    return self.PE\n",
        "  def call(self, inputs):\n",
        "    \"\"\"\n",
        "    inputs shape should be same as self.PE shape\n",
        "        \n",
        "      input_shape = tf.shape(inputs)\n",
        "      return inputs + self.PE[:, :input_shape[-2], :]\n",
        "\n",
        "    It has to be that way becuase we need to be able to get positional encoding for different lenght \n",
        "    for encoder and decoder, when we don`t know max lenght. SO we have to do encoding with bigger buffer\n",
        "    and take what we need only.\n",
        "\n",
        "    max_sentence_len in should be bigger or equal as longest input we predict we can get\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = tf.shape(inputs)\n",
        "    return inputs + self.PE[:, :input_shape[-2], :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dqxOYEMvhs4n",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttentionLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_size, heads_number, dtype=tf.float32, **kwargs):\n",
        "    super(MultiHeadAttentionLayer, self).__init__(dtype=tf.float32, **kwargs)\n",
        "    \"\"\"\n",
        "    return shape : [batch_size, sequence_len, d_model]\n",
        "    heads_number - tell how many heads will be processed at same time\n",
        "    d_model - model size ; equal to embedding_size\n",
        "    \"\"\"\n",
        "    self.heads_number = heads_number\n",
        "    self.d_model = embedding_size\n",
        "    self.w_q = tf.keras.layers.Dense(self.d_model)\n",
        "    self.w_k = tf.keras.layers.Dense(self.d_model)\n",
        "    self.w_v = tf.keras.layers.Dense(self.d_model)\n",
        "\n",
        "    self.outputLayer = tf.keras.layers.Dense(self.d_model)\n",
        "\n",
        "  # similar to dot attention but with scaling added\n",
        "  def ScaledDotProductAttention(self, v, k, q, sequence_mask):\n",
        "    \"\"\"\n",
        "    q shape [batch_size, num_heads, q_seq_len, depth_q]\n",
        "    k shape [batch_size, num_heads, k_seq_len, depth_k]\n",
        "    v shape [batch_size, num_heads, v_seq_len, depth_v]\n",
        "\n",
        "    output contex shape [batch_size, num_heads, q_seq_len, depth_v]\n",
        "    \"\"\"\n",
        "    # matmul(q,k,v)\n",
        "    # resultion shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
        "    qk_matmul = tf.matmul(q, k, transpose_b=True)\n",
        "    # scaling tf.cast is needed here because tf.sqrt needs float32 type\n",
        "    # score shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
        "    score = qk_matmul*tf.math.sqrt(tf.cast(k.shape[-1], dtype=tf.float32))\n",
        "    # optional mask\n",
        "    # mask should be shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
        "    # for example [\n",
        "    #             [0, 1, 1]\n",
        "    #             [0, 0, 1]\n",
        "    #             ] shape == (2, 3)\n",
        "    # we`re adding big negative number, because we only care about present/past words that are przedicted\n",
        "    if sequence_mask is not None:\n",
        "      #print(\" mask is not none\")\n",
        "      #print(\"sequence_mask shape {}\\nscore shape {}\" .format(sequence_mask.shape, score.shape))\n",
        "      score += sequence_mask*-1e-8\n",
        "    # softmax\n",
        "    # attention_weights shape [batch_size, num_heads, q_seq_len, k_seq_len]\n",
        "    attention_weights = tf.nn.softmax(score, axis=-1)\n",
        "    # matmul(res, V)\n",
        "    # contex shape [batch_size, num_heads, q_seq_len, depth_v]\n",
        "    context = tf.matmul(attention_weights, v)\n",
        "    return context\n",
        "\n",
        "  def splitHeads(self, data):\n",
        "    # new shape [batch_size, sequence_len, heads_number, d_model//heads_number]\n",
        "    data = tf.reshape(data, (data.shape[0], data.shape[1], self.heads_number, data.shape[-1]//self.heads_number))\n",
        "    # transpose dimentions to [batch_size, heads_number, sequence_len, d_model//heads_number]\n",
        "    return tf.transpose(data, perm=[0,2,1,3])\n",
        "\n",
        "  def call(self, q, k, v, sequence_mask):\n",
        "    \"\"\"\n",
        "    q shape [batch_size, sequence_len, d_model]\n",
        "    k shape [batch_size, sequence_len, d_model]\n",
        "    v shape [batch_size, sequence_len, d_model]\n",
        "\n",
        "    after first operations shapes are the same\n",
        "    next we have to split d_model into heads_number of subbatches\n",
        "    new shape after reshape only should be : [batch_size, sequence_len, heads_number, d_model//heads_number]\n",
        "    next shape should be transposed to : [batch_size, heads_number, sequence_len, d_model//heads_number]\n",
        "    where :\n",
        "      new_d_model = d_model/heads_number\n",
        "    \n",
        "    next make scaled dot-product attention on resulting q,k,v\n",
        "\n",
        "    next concat returning data to get shape : [batch_size, sequence_len, d_model]\n",
        "    in order to do this we have to transpose context_vector to get [batch_size, sequence_len, heads_number, d_model//heads_number]\n",
        "\n",
        "    next put it throug dense layer (d_model) in order to get output\n",
        "    \"\"\"\n",
        "    #print(\"q shape {}\\nk shape {}\\n v shape {}\" .format(q.shape, k.shape, v.shape))\n",
        "    q = self.w_q(q)\n",
        "    k = self.w_k(k)\n",
        "    v = self.w_v(v)\n",
        "    #print(\"AFTER Dense\\n  q shape {}\\n  k shape {}\\n  v shape {}\" .format(q.shape, k.shape, v.shape))\n",
        "\n",
        "    q = self.splitHeads(q)\n",
        "    k = self.splitHeads(k)\n",
        "    v = self.splitHeads(v)\n",
        "    #print(\"AFTER SPLIT\\n  q shape {}\\n  k shape {}\\n  v shape {}\" .format(q.shape, k.shape, v.shape))\n",
        "\n",
        "    context_vector = self.ScaledDotProductAttention(q, k, v, sequence_mask)\n",
        "    #print(\"context_vector shape :\", context_vector.shape)\n",
        "\n",
        "    context_vector = tf.transpose(context_vector, perm=[0,2,1,3])\n",
        "    #print(\"context_vector  transposed shape :\", context_vector.shape)\n",
        "    context_vector = tf.reshape(context_vector, (context_vector.shape[0], context_vector.shape[1], self.d_model))\n",
        "    #print(\"context_vector  reshapeed shape :\", context_vector.shape)\n",
        "\n",
        "    return self.outputLayer(context_vector)\n",
        "\n",
        "embed_size = 10; max_steps = 3; vocab_size = 100\n",
        "\n",
        "q = tf.random.uniform((1, max_steps, embed_size))  # shape [batch_size, sequence_len, embedding_size]\n",
        "mhatt = MultiHeadAttentionLayer(embed_size, 5)\n",
        "mhatt_output = mhatt(q, k=q, v=q, sequence_mask=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I4GNTftVHb5x",
        "colab": {}
      },
      "source": [
        "def feedForwardnetwork(dff, d_model):\n",
        "  \"\"\"\n",
        "  according to paper dff=2048 and d_model =512\n",
        "  but d_model should be same as embedding_size/d_model in MultiHeadAttention\n",
        "  ffn(x) = max(0, xW_1 + b+1)W_2 + b_2\n",
        "  where max(0, ...) -> relu activation\n",
        "  \"\"\"\n",
        "  ffNetwork = tf.keras.Sequential()\n",
        "  ffNetwork.add(tf.keras.layers.Dense(dff, activation=\"relu\"))\n",
        "  ffNetwork.add(tf.keras.layers.Dense(d_model))\n",
        "  return ffNetwork\n",
        "\n",
        "def makeSequenceMask(seq_len):\n",
        "  \"\"\"\n",
        "  mask should be size [1, 1, seq_len, seq_len]\n",
        "  first two sizes are batch_szie, num_heads to make this matrix broadcastable\n",
        "  it should be in form \n",
        "  [\n",
        "    [0, 1, 1, 1]\n",
        "    [0, 0, 1, 1]\n",
        "    [0, 0, 0, 1]\n",
        "    [0, 0, 0, 0]\n",
        "  ]\n",
        "  \"\"\"\n",
        "  mask_array = np.ones((seq_len, seq_len))\n",
        "  mask_array = np.triu(mask_array, 1)\n",
        "  return tf.constant(mask_array, dtype=tf.float32)\n",
        "\n",
        "def makePaddingMask(sequence):\n",
        "  mask = tf.math.equal(sequence, 0)\n",
        "  mask =  tf.cast(mask, tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y-_p_e0UNCpG",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_size, heads_number, dff, dtype=tf.float32, **kwargs):\n",
        "    super(EncoderLayer, self).__init__(dtype, **kwargs)\n",
        "\n",
        "    self.d_model = embedding_size\n",
        "    self.multiHeadAttention = MultiHeadAttentionLayer(embedding_size, heads_number)\n",
        "\n",
        "    self.normalizationFirst = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.normalizationSecond = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropoutFirst = tf.keras.layers.Dropout(0.2)\n",
        "    self.dropoutSecond = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "    self.ffNetwork = feedForwardnetwork(dff, self.d_model)\n",
        "\n",
        "  def call(self, encoder_input, mask, training_enabled):\n",
        "    # shortcut_data shape [batch_size, max_sentence_len, embedding_size]\n",
        "    shortcut_data = encoder_input\n",
        "\n",
        "    # mhatt_output shape [batch_size, max_sentence_len, embedding_size]\n",
        "    mhatt_output = self.multiHeadAttention(encoder_input, encoder_input, encoder_input, mask)\n",
        "    mhatt_output = self.dropoutFirst(mhatt_output, training=training_enabled)\n",
        "    mhatt_output += shortcut_data\n",
        "    mhatt_output = self.normalizationFirst(mhatt_output)\n",
        "\n",
        "    shortcut_data = mhatt_output\n",
        "\n",
        "    ffNet_output = self.ffNetwork(mhatt_output)\n",
        "    ffNet_output = self.dropoutSecond(ffNet_output, training=training_enabled)\n",
        "    ffNet_output += shortcut_data\n",
        "    ffNet_output = self.normalizationSecond(ffNet_output)\n",
        "\n",
        "    return ffNet_output\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  \"\"\"\n",
        "  Encoder flow :\n",
        "\n",
        "  - Embedding \n",
        "  - Positional Encoding\n",
        "  - Input = Embedding + Positional Encoding\n",
        "  --------------------REPEAT N Times--------------------\n",
        "  - Multi-head Attention layer\n",
        "  - Input + Multi-Head Attention layer added together \n",
        "  - previous Normalized (1)\n",
        "  - Feed Forward Network (2)\n",
        "  - (1) added to (2) and Normmalized\n",
        "  ------------------------------------------------------\n",
        "  - Encoder output \n",
        "  \"\"\"\n",
        "  def __init__(self, embedding_size, max_sentence_len, vocab_size, blocks_amount, heads_number, dff):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    assert (embedding_size//heads_number)%2==0\n",
        "    self.blocks_amount = blocks_amount\n",
        "    self.d_model = embedding_size\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "    self.positionalEncoding = PositionalEncodingLayer(embedding_size, max_sentence_len)\n",
        "\n",
        "    self.encoderBlocks = [EncoderLayer(embedding_size, heads_number, dff) for _ in range(blocks_amount)]\n",
        "  \n",
        "  def call(self, encoder_input, mask, training_enabled=False):\n",
        "    # sequence shape [batch_size, max_sentence_len]\n",
        "    embedded_seq = self.embedding(encoder_input)\n",
        "    # according to paper https://arxiv.org/pdf/1706.03762.pdf\n",
        "    # embedding is multiplied by sqrt(d_model). Point 3.4\n",
        "    embedded_seq*=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    # embedded_seq shape [batch_szie, max_sentence_len, embedding_size]\n",
        "    data = self.positionalEncoding(embedded_seq)\n",
        "    #------------------------- loop though all blocks -------------------------\n",
        "    for i in range(self.blocks_amount):\n",
        "      #print(\"               BLOCK \", i+1)\n",
        "      data = self.encoderBlocks[i](data, mask, training_enabled) \n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8T85ncKrVRYC",
        "outputId": "cb6d02e1-b836-411a-e0d6-dfa7cce97051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "data = np.ones((32, 10))\n",
        "print(\"input shape \", data.shape)\n",
        "padding_mask = makePaddingMask(data)\n",
        "\n",
        "encoder = Encoder(embedding_size=10,\n",
        "                  max_sentence_len=1000,\n",
        "                  vocab_size=100,\n",
        "                  blocks_amount=3,\n",
        "                  heads_number=5, \n",
        "                  dff=2048)\n",
        "encoder_out  = encoder(data, mask=padding_mask)\n",
        "print(encoder_out.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape  (32, 10)\n",
            "WARNING:tensorflow:Layer encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "(32, 10, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YhbwxVGBVwzP",
        "outputId": "d03e12e0-48e6-4eff-a1b6-fd6fc973deaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "Decoder flow :\n",
        "\n",
        "- Embedding \n",
        "- Positional Encoding\n",
        "- Input = Embedding + Positional Encoding\n",
        "--------------------REPEAT N Times--------------------\n",
        "- Masked Multi-head Attention layer with elements_mask\n",
        "- Input + Masked Multi-Head Attention layer added together \n",
        "- previous Normalized (1) \n",
        "- Multi-head Attention layer v, k from Encoder output | q from previous point with padding mask\n",
        "- (1) + Multi-head Attention layer added together\n",
        "- previous normalized\n",
        "- Feed Forward Network (2)\n",
        "- (1) added to (2) and Normalized\n",
        "------------------------------------------------------\n",
        "- Decoder output\n",
        "- Linear layer\n",
        "- softmax\n",
        "\"\"\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDecoder flow :\\n\\n- Embedding \\n- Positional Encoding\\n- Input = Embedding + Positional Encoding\\n--------------------REPEAT N Times--------------------\\n- Masked Multi-head Attention layer with elements_mask\\n- Input + Masked Multi-Head Attention layer added together \\n- previous Normalized (1) \\n- Multi-head Attention layer v, k from Encoder output | q from previous point with padding mask\\n- (1) + Multi-head Attention layer added together\\n- previous normalized\\n- Feed Forward Network (2)\\n- (1) added to (2) and Normalized\\n------------------------------------------------------\\n- Decoder output\\n- Linear layer\\n- softmax\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YrE1qDbL3i0G",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_size, heads_number, dff, dtype=tf.float32, **kwargs):\n",
        "    super(DecoderLayer, self).__init__(dtype, **kwargs)\n",
        "\n",
        "    self.d_model = embedding_size\n",
        "    self.multiHeadAttentionFirst = MultiHeadAttentionLayer(embedding_size, heads_number)\n",
        "    self.multiHeadAttentionSecond = MultiHeadAttentionLayer(embedding_size, heads_number)\n",
        "\n",
        "    self.normalizationFirst = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.normalizationSecond = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.normalizationThird = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropoutFirst = tf.keras.layers.Dropout(0.2)\n",
        "    self.dropoutSecond = tf.keras.layers.Dropout(0.2)\n",
        "    self.dropoutThird = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "    self.ffNetwork = feedForwardnetwork(dff, self.d_model)\n",
        "\n",
        "  def call(self, decoder_input, encoder_output, pad_mask, elements_mask, training_enabled):\n",
        "    # shortcut_data shape [batch_szie, max_sentence_len, embedding_size]\n",
        "    shortcut_data = decoder_input\n",
        "      \n",
        "    # mhatt_output shape [batch_size, max_sentence_len, embedding_size]\n",
        "    mhatt_output = self.multiHeadAttentionFirst(decoder_input, decoder_input, decoder_input, elements_mask)\n",
        "    mhatt_output = self.dropoutFirst(mhatt_output, training=training_enabled)\n",
        "    # add & Norm\n",
        "    mhatt_output += shortcut_data\n",
        "    mhatt_output = self.normalizationFirst(mhatt_output)\n",
        "\n",
        "    shortcut_data = mhatt_output\n",
        "    mhatt_output = self.multiHeadAttentionSecond(encoder_output, encoder_output, mhatt_output, pad_mask)\n",
        "    mhatt_output = self.dropoutSecond(mhatt_output, training=training_enabled)\n",
        "    mhatt_output += shortcut_data\n",
        "    mhatt_output = self.normalizationSecond(mhatt_output)\n",
        "\n",
        "    shortcut_data = mhatt_output\n",
        "    ffn_output = self.ffNetwork(mhatt_output)\n",
        "    ffn_output = self.dropoutThird(ffn_output, training=training_enabled)\n",
        "    ffn_output += shortcut_data\n",
        "    ffNet_output = self.normalizationThird(ffn_output)\n",
        "\n",
        "    return ffNet_output\n",
        "\n",
        "class Decoder(tf.keras.models.Model):\n",
        "  \"\"\"\n",
        "  Decoder flow :\n",
        "\n",
        "  - Embedding \n",
        "  - Positional Encoding\n",
        "  - Input = Embedding + Positional Encoding\n",
        "  --------------------REPEAT N Times--------------------\n",
        "  - Masked Multi-head Attention layer with elements_mask\n",
        "  - Input + Masked Multi-Head Attention layer added together \n",
        "  - previous Normalized (1) \n",
        "  - Multi-head Attention layer v, k from Encoder output | q from previous point with padding mask\n",
        "  - (1) + Multi-head Attention layer added together\n",
        "  - previous normalized\n",
        "  - Feed Forward Network (2)\n",
        "  - (1) added to (2) and Normalized\n",
        "  ------------------------------------------------------\n",
        "  - Decoder output\n",
        "\n",
        "  decoder masks are :\n",
        "    - encoder_padding_mask - padding mask made on encoder input data\n",
        "    - decoder sequences mask - sequence mask made on decoder input data\n",
        "  \"\"\"\n",
        "  def __init__(self, embedding_size, max_sentence_len, vocab_size, blocks_amount, heads_number, dff):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    assert (embedding_size//heads_number)%2==0\n",
        "    self.blocks_amount = blocks_amount\n",
        "    self.d_model = embedding_size\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "    self.positionalEncoding = PositionalEncodingLayer(embedding_size, max_sentence_len)\n",
        "\n",
        "    self.decoderBlocks = [DecoderLayer(embedding_size, heads_number, dff) for _ in range(blocks_amount)]\n",
        "\n",
        "  def call(self, encoder_output, decoder_input, pad_mask, elements_mask, training_enabled=False):\n",
        "\n",
        "    # sequence shape [batch_size, max_sentence_len]\n",
        "    embedded_seq = self.embedding(decoder_input)\n",
        "    # according to paper https://arxiv.org/pdf/1706.03762.pdf\n",
        "    # embedding is multiplied by sqrt(d_model). Point 3.4\n",
        "    embedded_seq*=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    # embedded_seq shape [batch_szie, max_sentence_len, embedding_size]\n",
        "    data = self.positionalEncoding(embedded_seq)\n",
        "    #------------------------- loop though all blocks -------------------------\n",
        "    for i in range(self.blocks_amount):\n",
        "      #print(\"               BLOCK \", i+1)\n",
        "      data = self.decoderBlocks[i](data, encoder_output, pad_mask, elements_mask, training_enabled)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F8Wb0q1bvlxa",
        "outputId": "c9d0c99c-8387-4092-d46e-4d65b8f2addb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "input_data = np.ones((32, max_steps))\n",
        "output_data = tf.random.uniform((32, 15))\n",
        "mask = makeSequenceMask(output_data.shape[1])\n",
        "print(\"Decoder input shape \", data.shape)\n",
        "blocks_amount = 2\n",
        "heads = 5\n",
        "en_vocab_size = 100\n",
        "fr_vocab_size = 200\n",
        "decoder = Decoder(embedding_size=10,\n",
        "                  max_sentence_len=1000,\n",
        "                  vocab_size=100,\n",
        "                  blocks_amount=3,\n",
        "                  heads_number=5, \n",
        "                  dff=2048)\n",
        "\"\"\"\n",
        "decoder masks are :\n",
        "- encoder_padding_mask - padding mask made on encoder input data\n",
        "- decoder sequences mask - sequence mask made on decoder input data\n",
        "\"\"\"\n",
        "decoder_out  = decoder(encoder_out, output_data, pad_mask=padding_mask, elements_mask=mask)\n",
        "print(\"decoder_out \", decoder_out.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder input shape  (32, 10)\n",
            "decoder_out  (32, 15, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xM03dp3qwO_9",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.models.Model):\n",
        "  \"\"\"\n",
        "  Transformer flow:\n",
        "\n",
        "  - Encoder\n",
        "  - Decoder\n",
        "  - Dense\n",
        "\n",
        "   transformer_out shape = [batch_size, output_seq_len, output_vocab_size]\n",
        "   default trainng_enabled == False\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               embedding_size,\n",
        "               dff,\n",
        "               input_max_seq_length,\n",
        "               output_max_seq_length,\n",
        "               input_vocab_size,\n",
        "               output_vocab_size,\n",
        "               encoder_blocks,\n",
        "               decoder_blocks,\n",
        "               heads):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(embedding_size, input_max_seq_length, input_vocab_size, encoder_blocks, heads, dff)\n",
        "    self.decoder = Decoder(embedding_size, output_max_seq_length, output_vocab_size, decoder_blocks, heads, dff)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(output_vocab_size)\n",
        "\n",
        "  def call(self, input_seq, output_seq, pad_mask, words_mask, training_enabled=False):\n",
        "    \n",
        "    encoder_out = self.encoder(input_seq, mask=pad_mask, training_enabled=training_enabled)\n",
        "    decoder_out = self.decoder(encoder_out, output_seq, pad_mask=pad_mask, elements_mask=words_mask, training_enabled=training_enabled)\n",
        "\n",
        "    transformer_out = self.dense(decoder_out)\n",
        "    return transformer_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mrJPalvR37Xp",
        "outputId": "5c7a877a-8563-4634-aeae-dc49997dedf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "transformer_model = Transformer(embedding_size=512,\n",
        "                                dff=2048,\n",
        "                                input_max_seq_length=2000,\n",
        "                                output_max_seq_length=1855,\n",
        "                                input_vocab_size=4980,\n",
        "                                output_vocab_size=7001,\n",
        "                                encoder_blocks=4,\n",
        "                                decoder_blocks=2,\n",
        "                                heads=8)\n",
        "\n",
        "# input_data and output_data\n",
        "input_data = tf.random.uniform((64, 52), dtype=tf.int64, minval=0, maxval=100)\n",
        "output_data = tf.random.uniform((64, 29), dtype=tf.int64, minval=0, maxval=250)\n",
        "\n",
        "encoder_pad_mask = makePaddingMask(input_data)\n",
        "elements_mask = makeSequenceMask(output_data.shape[1])\n",
        "print(\"output_data \", output_data.shape)\n",
        "print(\"elements_mask \", elements_mask.shape)\n",
        "transformer_output = transformer_model(input_data, output_data, encoder_pad_mask, elements_mask)\n",
        "print(transformer_output.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output_data  (64, 29)\n",
            "elements_mask  (29, 29)\n",
            "(64, 29, 7001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r6QCBpOj4OAW",
        "colab": {}
      },
      "source": [
        "class customLearningRate(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  \"\"\"\n",
        "  according to Attention is all you need paper learning rate has custom scheduler:\n",
        "  there are two parameters : \n",
        "  - d_model\n",
        "  - warmup_steps ( in paper set to 4000)\n",
        "  according to paper https://arxiv.org/pdf/1706.03762.pdf\n",
        "  point 5.3 Optimizer\n",
        "  \"\"\"\n",
        "  def __init__(self, warmup_steps, d_model):\n",
        "    super(customLearningRate, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.warmup_steps = warmup_steps\n",
        "  \n",
        "  def __call__(self, step):\n",
        "    firstScheduler = step**(-0.5)\n",
        "    secondScheduler = step*self.warmup_steps**(-0.5)\n",
        "    return self.d_model**(-0.5)*tf.minimum(firstScheduler, secondScheduler)\n",
        "\n",
        "custom_learning_rate = customLearningRate(warmup_steps=4000,\n",
        "                                          d_model=512)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=custom_learning_rate,\n",
        "                                    beta_1=0.9,\n",
        "                                    beta_2=0.98,\n",
        "                                    epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LgYd2QMDr__v",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bq1qufXuXYqW",
        "outputId": "f21d37bd-c10c-45ff-b3eb-0874ec342d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# reading data\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "en_lines, fr_lines = read_data_files(data_dir, (\"small_vocab_en\", \"small_vocab_fr\"))\n",
        "\n",
        "#data = read_data(os.path.join(data_dir, \"fra-eng\"), \"fra.txt\")\n",
        "#en_lines, fr_lines = list(zip(*data))\n",
        "\n",
        "en_lines = [normalize(line) for line in en_lines]\n",
        "fr_lines = [normalize(line) for line in fr_lines]\n",
        "\n",
        "en_train, en_test, fr_train, fr_test = train_test_split(en_lines, fr_lines, shuffle=True, test_size=0.1)\n",
        "\n",
        "fr_train_in = ['<start> ' + line for line in fr_train]\n",
        "fr_train_out = [line + ' <end>' for line in fr_train]\n",
        "\n",
        "fr_test_in = ['<start> ' + line for line in fr_test]\n",
        "fr_test_out = [line + ' <end>' for line in fr_test]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading data from  ./NLP/data/small_vocab_en\n",
            "reading data from  ./NLP/data/small_vocab_fr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-WEi7CE-jQz_",
        "colab_type": "code",
        "outputId": "94bd1b16-6c64-45ef-d287-7496a79c052f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "fr_tokenizer = Tokenizer(filters='')\n",
        "en_tokenizer = Tokenizer(filters='')\n",
        "\n",
        "input_data = [fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train]\n",
        "fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train = tokenizeInput(input_data, fr_tokenizer)\n",
        "\n",
        "input_data = [en_train, en_test]\n",
        "en_train, en_test = tokenizeInput(input_data, en_tokenizer)\n",
        "\n",
        "en_vocab_size = len(en_tokenizer.word_index)+1\n",
        "fr_vocab_size = len(fr_tokenizer.word_index)+1\n",
        "print(\"en_vocab {}\\nfr_vocab {}\" .format(en_vocab_size, fr_vocab_size))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en_vocab 203\n",
            "fr_vocab 336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USbqEYeSjQ0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((en_train, fr_train_in, fr_train_out))\n",
        "train_dataset = train_dataset.shuffle(len(en_train), reshuffle_each_iteration=True)\\\n",
        "                                 .batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((en_test, fr_test_in, fr_test_out))\n",
        "test_dataset = test_dataset.shuffle(len(en_test), reshuffle_each_iteration=True)\\\n",
        "                               .batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yzgf-d3jQ0J",
        "colab_type": "code",
        "outputId": "d6a05a75-7856-4c0c-800e-b96c5abec547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Training batches per epoch :\", len(en_train)//BATCH_SIZE)\n",
        "\n",
        "num_layers = 4 # 6\n",
        "d_model = 128 # 512\n",
        "dff = 512  # 2048\n",
        "num_heads = 8 \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training batches per epoch : 1938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "yWYzmhBFjQ0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b6541f0-acf0-4ff7-80ea-4ce8e547ce99"
      },
      "source": [
        "transformer_model = Transformer(embedding_size=d_model,\n",
        "                                dff=dff,\n",
        "                                input_max_seq_length=2000,\n",
        "                                output_max_seq_length=1855,\n",
        "                                input_vocab_size=en_vocab_size,\n",
        "                                output_vocab_size=fr_vocab_size,\n",
        "                                encoder_blocks=num_layers,\n",
        "                                decoder_blocks=num_layers,\n",
        "                                heads=num_heads)\n",
        "test_losses = []\n",
        "train_losses = []\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "training_loss = tf.keras.metrics.Mean()\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True)\n",
        "\n",
        "def loss_fn(real, targets):\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, tf.int64)\n",
        "    loss = loss_object(targets, real, sample_weight=mask)\n",
        "    return tf.reduce_mean(loss)    \n",
        "\n",
        "@tf.function\n",
        "def train_step(input_data, real_data_in, real_data_out):\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoder_pad_mask = makePaddingMask(input_data)\n",
        "        elements_mask = makeSequenceMask(real_data_in.shape[1])\n",
        "        predicted_data = transformer_model(input_data, real_data_in, encoder_pad_mask, elements_mask, training_enabled=True)\n",
        "        \n",
        "        loss = loss_fn(predicted_data, real_data_out)\n",
        "  \n",
        "    trainable_vars = transformer_model.trainable_variables\n",
        "    grads = tape.gradient(loss, trainable_vars)\n",
        "    optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "    train_accuracy(real_data_out, predicted_data)\n",
        "    training_loss(loss)\n",
        "\n",
        "@tf.function\n",
        "def test_step(input_data, real_data_in, real_data_out):\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoder_pad_mask = makePaddingMask(input_data)\n",
        "        elements_mask = makeSequenceMask(real_data_in.shape[1])\n",
        "        predicted_data = transformer_model(input_data, real_data_in, encoder_pad_mask, elements_mask, training_enabled=False)\n",
        "        \n",
        "        loss = loss_fn(predicted_data, real_data_out)\n",
        "  \n",
        "    test_accuracy(real_data_out, predicted_data)\n",
        "    test_loss(loss)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    training_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "  \n",
        "    for batch, (en_data, fr_data_in, fr_train_out) in enumerate(train_dataset):\n",
        "        train_step(en_data, fr_data_in, fr_train_out)\n",
        "        if batch != 0 and (batch%500 == 0):\n",
        "          print(\"   Epoch {} batch {} loss {:.4f} accuracy {:.4f}\" .format(epoch+1, batch, training_loss.result(), train_accuracy.result()))\n",
        "    for _, (en_data, fr_data_in, fr_data_out) in enumerate(test_dataset):\n",
        "        test_step(en_data, fr_data_in, fr_data_out)\n",
        "        \n",
        "    print ('Epoch {} training Loss {:.4f} Accuracy {:.4f}  test Loss {:.4f} Accuracy {:.4f}' .format( \\\n",
        "                                                epoch + 1, \n",
        "                                                training_loss.result(), \n",
        "                                                train_accuracy.result(),\n",
        "                                                test_loss.result(),\n",
        "                                                test_accuracy.result()))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Epoch 1 batch 500 loss 2.4579 accuracy 0.0694\n",
            "   Epoch 1 batch 1000 loss 2.2643 accuracy 0.0864\n",
            "   Epoch 1 batch 1500 loss 1.9404 accuracy 0.1486\n",
            "Epoch 1 training Loss 1.7098 Accuracy 0.1952  test Loss 0.8151 Accuracy 0.4394\n",
            "   Epoch 2 batch 500 loss 0.7326 accuracy 0.4002\n",
            "   Epoch 2 batch 1000 loss 0.6688 accuracy 0.4178\n",
            "   Epoch 2 batch 1500 loss 0.6164 accuracy 0.4338\n",
            "Epoch 2 training Loss 0.5724 Accuracy 0.4481  test Loss 0.3417 Accuracy 0.5801\n",
            "   Epoch 3 batch 500 loss 0.3013 accuracy 0.5331\n",
            "   Epoch 3 batch 1000 loss 0.2468 accuracy 0.5509\n",
            "   Epoch 3 batch 1500 loss 0.1996 accuracy 0.5666\n",
            "Epoch 3 training Loss 0.1687 Accuracy 0.5766  test Loss 0.0373 Accuracy 0.6793\n",
            "   Epoch 4 batch 500 loss 0.0469 accuracy 0.6158\n",
            "   Epoch 4 batch 1000 loss 0.0408 accuracy 0.6182\n",
            "   Epoch 4 batch 1500 loss 0.0364 accuracy 0.6191\n",
            "Epoch 4 training Loss 0.0334 Accuracy 0.6198  test Loss 0.0118 Accuracy 0.6865\n",
            "   Epoch 5 batch 500 loss 0.0185 accuracy 0.6239\n",
            "   Epoch 5 batch 1000 loss 0.0166 accuracy 0.6241\n",
            "   Epoch 5 batch 1500 loss 0.0154 accuracy 0.6245\n",
            "Epoch 5 training Loss 0.0145 Accuracy 0.6249  test Loss 0.0063 Accuracy 0.6880\n",
            "   Epoch 6 batch 500 loss 0.0092 accuracy 0.6264\n",
            "   Epoch 6 batch 1000 loss 0.0087 accuracy 0.6263\n",
            "   Epoch 6 batch 1500 loss 0.0083 accuracy 0.6267\n",
            "Epoch 6 training Loss 0.0079 Accuracy 0.6267  test Loss 0.0034 Accuracy 0.6887\n",
            "   Epoch 7 batch 500 loss 0.0063 accuracy 0.6268\n",
            "   Epoch 7 batch 1000 loss 0.0059 accuracy 0.6268\n",
            "   Epoch 7 batch 1500 loss 0.0056 accuracy 0.6272\n",
            "Epoch 7 training Loss 0.0053 Accuracy 0.6274  test Loss 0.0028 Accuracy 0.6889\n",
            "   Epoch 8 batch 500 loss 0.0039 accuracy 0.6276\n",
            "   Epoch 8 batch 1000 loss 0.0041 accuracy 0.6282\n",
            "   Epoch 8 batch 1500 loss 0.0039 accuracy 0.6279\n",
            "Epoch 8 training Loss 0.0037 Accuracy 0.6278  test Loss 0.0022 Accuracy 0.6890\n",
            "   Epoch 9 batch 500 loss 0.0028 accuracy 0.6281\n",
            "   Epoch 9 batch 1000 loss 0.0028 accuracy 0.6280\n",
            "   Epoch 9 batch 1500 loss 0.0027 accuracy 0.6280\n",
            "Epoch 9 training Loss 0.0026 Accuracy 0.6281  test Loss 0.0021 Accuracy 0.6892\n",
            "   Epoch 10 batch 500 loss 0.0024 accuracy 0.6283\n",
            "   Epoch 10 batch 1000 loss 0.0023 accuracy 0.6276\n",
            "   Epoch 10 batch 1500 loss 0.0023 accuracy 0.6280\n",
            "Epoch 10 training Loss 0.0022 Accuracy 0.6282  test Loss 0.0019 Accuracy 0.6891\n",
            "   Epoch 11 batch 500 loss 0.0016 accuracy 0.6281\n",
            "   Epoch 11 batch 1000 loss 0.0016 accuracy 0.6278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a1cf5054975d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0men_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_data_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_train_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_data_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_train_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   Epoch {} batch {} loss {:.4f} accuracy {:.4f}\"\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHBils3ywVrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}