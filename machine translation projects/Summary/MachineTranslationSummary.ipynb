{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "from multiprocessing import Process\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sys.path.insert(0, r\"../utilities/\")\n",
    "sys.path.insert(0, r\"../Seq2Seq/\")\n",
    "sys.path.insert(0, r\"../Seq2SeqAttention/\")\n",
    "sys.path.insert(0, r\"../Transformer/\")\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Seq2SeqTrainer import Seq2SeqTrainer\n",
    "from Seq2SeqAttentionTrainer import Seq2SeqAttentionTrainer\n",
    "from TransformerTrainer import TransformerTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlots(losses, accuracy, name):\n",
    "    train_losses, test_losses = losses \n",
    "    train_accuracyVec, test_accuracyVec = accuracy\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    fig_plot = fig.add_subplot()\n",
    "    fig_plot.plot(train_losses, label=\"train_loss\")\n",
    "    fig_plot.plot(test_losses, label=\"test_loss\")\n",
    "    fig_plot.legend(loc=\"upper right\")\n",
    "    fig_plot.set_xlabel(\"epoch\")\n",
    "    fig_plot.set_ylabel(\"loss\")\n",
    "    fig_plot.grid(linestyle=\"--\")\n",
    "    fig.savefig(\"losses_plot_\" + name +  \".png\")\n",
    "    fig.show()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig_plot = fig.add_subplot()\n",
    "    fig_plot.plot(train_accuracyVec, label=\"train_accuracy\")\n",
    "    fig_plot.plot(test_accuracyVec, label=\"test_accuracy\")\n",
    "    fig_plot.legend(loc=\"lower right\")\n",
    "    fig_plot.set_xlabel(\"epoch\")\n",
    "    fig_plot.set_ylabel(\"accuracy\")\n",
    "    fig_plot.grid(linestyle=\"--\")\n",
    "    fig.savefig(\"accuracy_plot.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from  ../data/fra-eng/fra.txt\n",
      "en_vocab 8397\n",
      "fr_vocab 13499\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "# reading data\n",
    "\n",
    "data = read_data(os.path.join(data_dir, \"fra-eng\"), \"fra.txt\")\n",
    "en_lines, fr_lines = list(zip(*data))\n",
    "en_lines_raw, fr_lines_raw = shuffle(en_lines, fr_lines)\n",
    "\n",
    "en_lines = en_lines_raw[:40000]\n",
    "fr_lines = fr_lines_raw[:40000]\n",
    "\n",
    "en_lines = [normalize(line) for line in en_lines]\n",
    "fr_lines = [normalize(line) for line in fr_lines]\n",
    "\n",
    "en_train, en_test, fr_train, fr_test = train_test_split(en_lines, fr_lines, shuffle=True, test_size=0.1)\n",
    "\n",
    "en_lines = en_test\n",
    "fr_lines = fr_test\n",
    "\n",
    "fr_train_in = ['<start> ' + line for line in fr_train]\n",
    "fr_train_out = [line + ' <end>' for line in fr_train]\n",
    "\n",
    "fr_test_in = ['<start> ' + line for line in fr_test]\n",
    "fr_test_out = [line + ' <end>' for line in fr_test]\n",
    "\n",
    "fr_tokenizer = Tokenizer(filters='')\n",
    "en_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "input_data = [fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train]\n",
    "fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train = tokenizeInput(input_data,\n",
    "                                                                                      fr_tokenizer)\n",
    "input_data = [en_train, en_test]\n",
    "en_train, en_test = tokenizeInput(input_data, en_tokenizer)\n",
    "\n",
    "en_vocab_size = len(en_tokenizer.word_index)+1\n",
    "fr_vocab_size = len(fr_tokenizer.word_index)+1\n",
    "print(\"en_vocab {}\\nfr_vocab {}\" .format(en_vocab_size, fr_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_TEXTS\n",
      "I'm not feeling particularly hungry.  -  Je ne ressens pas particulièrement la faim.\n",
      "She's a quiet person.  -  Elle est d'un naturel calme.\n",
      "We all hate Tom.  -  Nous détestons tous Tom.\n",
      "Tom wouldn't really do that, would he?  -  Tom ne ferait pas vraiment cela, n'est-ce pas ?\n",
      "I'm in love with you and I want to marry you.  -  Je suis amoureux de toi et je veux t'épouser.\n",
      "Where are your gloves?  -  Où sont tes gants ?\n",
      "You two are really kind.  -  Vous êtes vraiment gentils tous les deux.\n",
      "What you make is small potatoes compared to the boss's salary.  -  Ce que tu gagnes est de la roupie de sansonnet, comparé au salaire du patron.\n",
      "Mama cried.  -  Maman pleurait.\n",
      "How did you come by this painting?  -  Comment êtes-vous entré en possession de cette toile ?\n"
     ]
    }
   ],
   "source": [
    "prediction_idx = np.random.randint(low=40000, high=len(en_lines_raw), size=10)\n",
    "print(\"TEST_TEXTS\")\n",
    "test_text = [(en_lines_raw[idx], fr_lines_raw[idx]) for idx in prediction_idx]\n",
    "for (en,fr) in test_text:\n",
    "    print(en, \" - \", fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIZE = 512\n",
    "EMBEDDING_SIZE = 256\n",
    "BATCH_SIZE= 64\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Seq2SeqPredictions():\n",
    "    trainer = Seq2SeqTrainer(BATCH_SIZE, LSTM_SIZE, EMBEDDING_SIZE, predict_every=20)\n",
    "    losses, accuracy = trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_lines, fr_lines], [en_tokenizer, fr_tokenizer], EPOCHS)\n",
    "    makePlots(losses, accuracy, \"Seq2Seq\")\n",
    "    for (en_text, fr_text) in test_text:\n",
    "        trainer.predict(en_text, fr_text)\n",
    "\n",
    "def Seq2SeqAttentionPredictions():\n",
    "    trainer = Seq2SeqAttentionTrainer(BATCH_SIZE, LSTM_SIZE, EMBEDDING_SIZE, predict_every=20)\n",
    "    losses, accuracy = trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_lines, fr_lines], [en_tokenizer, fr_tokenizer], EPOCHS, \"concat\")\n",
    "    makePlots(losses, accuracy, \"Seq2SeqAttention\")\n",
    "    for (en_text, fr_text) in test_text:\n",
    "        trainer.predict(en_text, fr_text, print_prediction=True)\n",
    "\n",
    "def TransformerPredictions():\n",
    "    BATCH_SIZE = 64\n",
    "    num_layers = 4 # 6\n",
    "    d_model = 256 # 512\n",
    "    dff = 512  # 2048\n",
    "    num_heads = 8\n",
    "    trainer = TransformerTrainer(BATCH_SIZE, num_layers, d_model, dff, num_heads, predict_every=20)\n",
    "    losses, accuracy= trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_lines, fr_lines], [en_tokenizer, fr_tokenizer], EPOCHS)\n",
    "    makePlots(losses, accuracy, \"Transformer\")\n",
    "    for (en_text, fr_text) in test_text:\n",
    "        trainer.predict(en_text, fr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab 8397\n",
      "fr_vocab 13499\n",
      "Number of devices: 4\n",
      "creating dataset...\n",
      "dataset created\n",
      "input :  Were you born there ?\n",
      "output:  Etes-vous ne la-bas ?\n",
      "training from scratch\n",
      "starting training with 20 epochs with prediction each 20 epoch\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1 training Loss 50.4938 Accuracy 0.0333  test Loss 43.7839 Accuracy 0.0773\n",
      "Saving checkpoint for epoch 0: ./checkpoints/Seq2Seq/ckpt-1\n",
      "--------------PREDICTION--------------\n",
      "  English   :  Were you born there ?\n",
      "  Predicted :  je ne a .\n",
      "  Correct   :  Etes-vous ne la-bas ?\n",
      "------------END PREDICTION------------\n",
      "Epoch 2 training Loss 40.7831 Accuracy 0.0504  test Loss 38.8369 Accuracy 0.0937\n",
      "Epoch 3 training Loss 36.5514 Accuracy 0.0581  test Loss 35.8132 Accuracy 0.1032\n",
      "Epoch 4 training Loss 33.1215 Accuracy 0.0652  test Loss 33.4449 Accuracy 0.1148\n",
      "Epoch 5 training Loss 30.2794 Accuracy 0.0713  test Loss 31.6528 Accuracy 0.1213\n",
      "Epoch 6 training Loss 27.8997 Accuracy 0.0754  test Loss 29.9970 Accuracy 0.1268\n",
      "Saving checkpoint for epoch 5: ./checkpoints/Seq2Seq/ckpt-2\n",
      "Epoch 7 training Loss 25.9361 Accuracy 0.0795  test Loss 28.9365 Accuracy 0.1326\n",
      "Epoch 8 training Loss 24.2530 Accuracy 0.0834  test Loss 28.0010 Accuracy 0.1372\n",
      "Epoch 9 training Loss 22.7115 Accuracy 0.0871  test Loss 27.1076 Accuracy 0.1427\n",
      "Epoch 10 training Loss 21.2771 Accuracy 0.0906  test Loss 26.4662 Accuracy 0.1456\n",
      "Epoch 11 training Loss 19.9357 Accuracy 0.0941  test Loss 25.7555 Accuracy 0.1497\n",
      "Saving checkpoint for epoch 10: ./checkpoints/Seq2Seq/ckpt-3\n",
      "Epoch 12 training Loss 18.6682 Accuracy 0.0974  test Loss 25.2750 Accuracy 0.1528\n",
      "Epoch 13 training Loss 17.4830 Accuracy 0.1009  test Loss 24.7645 Accuracy 0.1555\n",
      "Epoch 14 training Loss 16.3654 Accuracy 0.1044  test Loss 24.3381 Accuracy 0.1583\n",
      "Epoch 15 training Loss 15.3208 Accuracy 0.1082  test Loss 24.0697 Accuracy 0.1611\n",
      "Epoch 16 training Loss 14.3057 Accuracy 0.1117  test Loss 23.7858 Accuracy 0.1629\n",
      "Saving checkpoint for epoch 15: ./checkpoints/Seq2Seq/ckpt-4\n",
      "Epoch 17 training Loss 13.3707 Accuracy 0.1153  test Loss 23.4264 Accuracy 0.1651\n",
      "Epoch 18 training Loss 12.5043 Accuracy 0.1187  test Loss 23.2608 Accuracy 0.1665\n",
      "Epoch 19 training Loss 11.6612 Accuracy 0.1224  test Loss 23.0853 Accuracy 0.1681\n",
      "Epoch 20 training Loss 10.8838 Accuracy 0.1255  test Loss 22.9929 Accuracy 0.1694\n",
      "--------------PREDICTION--------------\n",
      "  English   :  I'm not feeling particularly hungry.\n",
      "  Predicted :  ne me regarde pas ?\n",
      "  Correct   :  Je ne ressens pas particulièrement la faim.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  She's a quiet person.\n",
      "  Predicted :  un autre !\n",
      "  Correct   :  Elle est d'un naturel calme.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  We all hate Tom.\n",
      "  Predicted :  nous sommes tous .\n",
      "  Correct   :  Nous détestons tous Tom.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  Tom wouldn't really do that, would he?\n",
      "  Predicted :  tom vraiment vraiment .\n",
      "  Correct   :  Tom ne ferait pas vraiment cela, n'est-ce pas ?\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  I'm in love with you and I want to marry you.\n",
      "  Predicted :  ou devrais-je vous montrer que je suis en train de tom ?\n",
      "  Correct   :  Je suis amoureux de toi et je veux t'épouser.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  Where are your gloves?\n",
      "  Predicted :  ou est vos !\n",
      "  Correct   :  Où sont tes gants ?\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  You two are really kind.\n",
      "  Predicted :  vous aimez le plus ?\n",
      "  Correct   :  Vous êtes vraiment gentils tous les deux.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  What you make is small potatoes compared to the boss's salary.\n",
      "  Predicted :  que tu es le plus grand au printemps !\n",
      "  Correct   :  Ce que tu gagnes est de la roupie de sansonnet, comparé au salaire du patron.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  Mama cried.\n",
      "  Predicted :  calme-toi .\n",
      "  Correct   :  Maman pleurait.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  How did you come by this painting?\n",
      "  Predicted :  comment vous etes-vous fait ca ?\n",
      "  Correct   :  Comment êtes-vous entré en possession de cette toile ?\n",
      "------------END PREDICTION------------\n"
     ]
    }
   ],
   "source": [
    "p = Process(target=Seq2SeqPredictions, args=())\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab 8397\n",
      "fr_vocab 13499\n",
      "Number of devices: 4\n",
      "creating dataset...\n",
      "dataset created\n",
      "input :  Were you born there ?\n",
      "output:  Etes-vous ne la-bas ?\n",
      "training from scratch\n",
      "starting training with 20 epochs with prediction each 20 epoch\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1 training Loss 1.0116 Accuracy 0.0281  test Loss 1.5228 Accuracy 0.0717\n",
      "Saving checkpoint for epoch 0: ./checkpoints/Seq2SeqAttention/ckpt-1\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence Were you born there ? \n",
      "       Predicted:  il est a . \n",
      "       Should be:  Etes-vous ne la-bas ? \n",
      "--------------------------END PREDICTION--------------------------\n",
      "Epoch 2 training Loss 0.8552 Accuracy 0.0465  test Loss 1.3885 Accuracy 0.0880\n",
      "Epoch 3 training Loss 0.7506 Accuracy 0.0559  test Loss 1.2250 Accuracy 0.1006\n",
      "Epoch 4 training Loss 0.6667 Accuracy 0.0639  test Loss 1.1385 Accuracy 0.1090\n",
      "Epoch 5 training Loss 0.6045 Accuracy 0.0700  test Loss 1.0698 Accuracy 0.1189\n",
      "Epoch 6 training Loss 0.5503 Accuracy 0.0757  test Loss 1.0113 Accuracy 0.1259\n",
      "Saving checkpoint for epoch 5: ./checkpoints/Seq2SeqAttention/ckpt-2\n",
      "Epoch 7 training Loss 0.5003 Accuracy 0.0811  test Loss 0.9449 Accuracy 0.1344\n",
      "Epoch 8 training Loss 0.4511 Accuracy 0.0872  test Loss 0.8724 Accuracy 0.1456\n",
      "Epoch 9 training Loss 0.3985 Accuracy 0.0948  test Loss 0.8087 Accuracy 0.1569\n",
      "Epoch 10 training Loss 0.3445 Accuracy 0.1037  test Loss 0.7422 Accuracy 0.1694\n",
      "Epoch 11 training Loss 0.2971 Accuracy 0.1115  test Loss 0.6985 Accuracy 0.1786\n",
      "Saving checkpoint for epoch 10: ./checkpoints/Seq2SeqAttention/ckpt-3\n",
      "Epoch 12 training Loss 0.2573 Accuracy 0.1184  test Loss 0.6669 Accuracy 0.1842\n",
      "Epoch 13 training Loss 0.2242 Accuracy 0.1244  test Loss 0.6405 Accuracy 0.1896\n",
      "Epoch 14 training Loss 0.1975 Accuracy 0.1297  test Loss 0.6277 Accuracy 0.1917\n",
      "Epoch 15 training Loss 0.1748 Accuracy 0.1341  test Loss 0.6133 Accuracy 0.1947\n",
      "Epoch 16 training Loss 0.1560 Accuracy 0.1380  test Loss 0.6129 Accuracy 0.1982\n",
      "Saving checkpoint for epoch 15: ./checkpoints/Seq2SeqAttention/ckpt-4\n",
      "Epoch 17 training Loss 0.1400 Accuracy 0.1415  test Loss 0.6038 Accuracy 0.1993\n",
      "Epoch 18 training Loss 0.1260 Accuracy 0.1445  test Loss 0.5976 Accuracy 0.2014\n",
      "Epoch 19 training Loss 0.1143 Accuracy 0.1470  test Loss 0.6032 Accuracy 0.2012\n",
      "Epoch 20 training Loss 0.1042 Accuracy 0.1494  test Loss 0.6015 Accuracy 0.2025\n",
      "Saving checkpoint for end at ./checkpoints/Seq2SeqAttention/ckpt-5\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence I'm not feeling particularly hungry. \n",
      "       Predicted:  refusent desir esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons esperons \n",
      "       Should be:  Je ne ressens pas particulièrement la faim. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence She's a quiet person. \n",
      "       Predicted:  roman billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet billet \n",
      "       Should be:  Elle est d'un naturel calme. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence We all hate Tom. \n",
      "       Predicted:  nous-memes nous-memes pouvons-nous dites-nous gens nous-memes pouvons-nous savais savais gens nous-memes pouvons-nous savais gens nous-memes pouvons-nous savais gens nous-memes pouvons-nous savais gens nous-memes pouvons-nous savais gens nous-memes pouvons-nous savais gens nous-memes pouvons-nous savais gens nous-memes pouvons-nous savais savais gens nous-memes \n",
      "       Should be:  Nous détestons tous Tom. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence Tom wouldn't really do that, would he? \n",
      "       Predicted:  tom tom tom tom parlerai vraiment pas . \n",
      "       Should be:  Tom ne ferait pas vraiment cela, n'est-ce pas ? \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence I'm in love with you and I want to marry you. \n",
      "       Predicted:  loyer loyer loyer loyer loyer loyer loyer loyer loyer loyer loyer loyer loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes loyer symptomes \n",
      "       Should be:  Je suis amoureux de toi et je veux t'épouser. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence Where are your gloves? \n",
      "       Predicted:  ou etes-vous votre faute ? \n",
      "       Should be:  Où sont tes gants ? \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence You two are really kind. \n",
      "       Predicted:  tu te es vraiment vraiment . \n",
      "       Should be:  Vous êtes vraiment gentils tous les deux. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence What you make is small potatoes compared to the boss's salary. \n",
      "       Predicted:  quoi que tu es de petit de riz caches . \n",
      "       Should be:  Ce que tu gagnes est de la roupie de sansonnet, comparé au salaire du patron. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence Mama cried. \n",
      "       Predicted:  pourquoi etait toi . \n",
      "       Should be:  Maman pleurait. \n",
      "--------------------------END PREDICTION--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence How did you come by this painting? \n",
      "       Predicted:  comment es-tu a toi contre ca . \n",
      "       Should be:  Comment êtes-vous entré en possession de cette toile ? \n",
      "--------------------------END PREDICTION--------------------------\n"
     ]
    }
   ],
   "source": [
    "p = Process(target=Seq2SeqAttentionPredictions, args=())\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab 8397\n",
      "fr_vocab 13499\n",
      "Number of devices: 4\n",
      "creating dataset...\n",
      "input :  Were you born there ?\n",
      "output:  Etes-vous ne la-bas ?\n",
      "training from scratch\n",
      "INFO:tensorflow:batch_all_reduce: 170 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 170 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1 training Loss 81.5533 Accuracy 0.0148  test Loss 74.8237 Accuracy 0.0333\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : Were you born there ?\n",
      "           Predicted : \n",
      "           Correct   : Etes-vous ne la-bas ?\n",
      "--------------------------END PREDICTION--------------------------\n",
      "Saving checkpoint for epoch 0: ./checkpoints/train/ckpt-1\n",
      "Epoch 2 training Loss 67.4874 Accuracy 0.0198  test Loss 57.0023 Accuracy 0.0587\n",
      "Epoch 3 training Loss 52.0406 Accuracy 0.0384  test Loss 46.8666 Accuracy 0.0797\n",
      "Epoch 4 training Loss 44.3819 Accuracy 0.0531  test Loss 40.2865 Accuracy 0.1012\n",
      "Epoch 5 training Loss 38.4556 Accuracy 0.0631  test Loss 35.8830 Accuracy 0.1141\n",
      "Epoch 6 training Loss 34.4342 Accuracy 0.0693  test Loss 33.0904 Accuracy 0.1238\n",
      "Saving checkpoint for epoch 5: ./checkpoints/train/ckpt-2\n",
      "Epoch 7 training Loss 31.4518 Accuracy 0.0748  test Loss 30.8035 Accuracy 0.1321\n",
      "Epoch 8 training Loss 28.8812 Accuracy 0.0799  test Loss 28.9016 Accuracy 0.1390\n",
      "Epoch 9 training Loss 26.5610 Accuracy 0.0849  test Loss 27.3597 Accuracy 0.1467\n",
      "Epoch 10 training Loss 24.3428 Accuracy 0.0900  test Loss 25.3891 Accuracy 0.1557\n",
      "Epoch 11 training Loss 21.9290 Accuracy 0.0965  test Loss 23.5191 Accuracy 0.1660\n",
      "Saving checkpoint for epoch 10: ./checkpoints/train/ckpt-3\n",
      "Epoch 12 training Loss 19.6095 Accuracy 0.1030  test Loss 21.9288 Accuracy 0.1733\n",
      "Epoch 13 training Loss 17.4605 Accuracy 0.1093  test Loss 20.3660 Accuracy 0.1828\n",
      "Epoch 14 training Loss 15.5025 Accuracy 0.1152  test Loss 18.9865 Accuracy 0.1898\n",
      "Epoch 15 training Loss 13.7059 Accuracy 0.1207  test Loss 18.0838 Accuracy 0.1939\n",
      "Epoch 16 training Loss 12.2261 Accuracy 0.1250  test Loss 17.5375 Accuracy 0.1998\n",
      "Saving checkpoint for epoch 15: ./checkpoints/train/ckpt-4\n",
      "Epoch 17 training Loss 10.9149 Accuracy 0.1289  test Loss 16.8419 Accuracy 0.2035\n",
      "Epoch 18 training Loss 9.7867 Accuracy 0.1323  test Loss 16.4544 Accuracy 0.2057\n",
      "Epoch 19 training Loss 8.7708 Accuracy 0.1355  test Loss 16.3688 Accuracy 0.2067\n",
      "Epoch 20 training Loss 7.9317 Accuracy 0.1383  test Loss 16.1498 Accuracy 0.2074\n",
      "Saving checkpoint for end at ./checkpoints/train/ckpt-5\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : I'm not feeling particularly hungry.\n",
      "           Predicted : ne me sens-tu pas particulierement particulierement .\n",
      "           Correct   : Je ne ressens pas particulièrement la faim.\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : She's a quiet person.\n",
      "           Predicted : un seul tranquille .\n",
      "           Correct   : Elle est d'un naturel calme.\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : We all hate Tom.\n",
      "           Predicted : nous detestent tous tous tous tous tous tous tous tous .\n",
      "           Correct   : Nous détestons tous Tom.\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : Tom wouldn't really do that, would he?\n",
      "           Predicted : tom ferait vraiment ferait vraiment tom .\n",
      "           Correct   : Tom ne ferait pas vraiment cela, n'est-ce pas ?\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : I'm in love with you and I want to marry you.\n",
      "           Predicted : amoureux de toi et je veux epouser .\n",
      "           Correct   : Je suis amoureux de toi et je veux t'épouser.\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : Where are your gloves?\n",
      "           Predicted : ou sont vos affaires .\n",
      "           Correct   : Où sont tes gants ?\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : You two are really kind.\n",
      "           Predicted : vous etes vraiment vraiment ?\n",
      "           Correct   : Vous êtes vraiment gentils tous les deux.\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : What you make is small potatoes compared to the boss's salary.\n",
      "           Predicted : ce que vous avez de cote est de la musique avec la musique douce .\n",
      "           Correct   : Ce que tu gagnes est de la roupie de sansonnet, comparé au salaire du patron.\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : Mama cried.\n",
      "           Predicted : maman a maman maman\n",
      "           Correct   : Maman pleurait.\n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "           English   : How did you come by this painting?\n",
      "           Predicted : comment etes-vous venu a ca ?\n",
      "           Correct   : Comment êtes-vous entré en possession de cette toile ?\n",
      "--------------------------END PREDICTION--------------------------\n"
     ]
    }
   ],
   "source": [
    "p = Process(target=TransformerPredictions, args=())\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
