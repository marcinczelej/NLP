{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "from multiprocessing import Process\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sys.path.insert(0, r\"../utilities/\")\n",
    "sys.path.insert(0, r\"../Seq2Seq/\")\n",
    "sys.path.insert(0, r\"../Seq2SeqAttention/\")\n",
    "sys.path.insert(0, r\"../Transformer/\")\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Seq2SeqTrainer import Seq2SeqTrainer\n",
    "from Seq2SeqAttentionTrainer import Seq2SeqAttentionTrainer\n",
    "from TransformerTrainer import TransformerTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlots(losses, accuracy, name):\n",
    "    train_losses, test_losses = losses \n",
    "    train_accuracyVec, test_accuracyVec = accuracy\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    fig_plot = fig.add_subplot()\n",
    "    fig_plot.plot(train_losses, label=\"train_loss\")\n",
    "    fig_plot.plot(test_losses, label=\"test_loss\")\n",
    "    fig_plot.legend(loc=\"upper right\")\n",
    "    fig_plot.set_xlabel(\"epoch\")\n",
    "    fig_plot.set_ylabel(\"loss\")\n",
    "    fig_plot.grid(linestyle=\"--\")\n",
    "    fig.savefig(\"losses_plot_\" + name +  \".png\")\n",
    "    fig.show()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig_plot = fig.add_subplot()\n",
    "    fig_plot.plot(train_accuracyVec, label=\"train_accuracy\")\n",
    "    fig_plot.plot(test_accuracyVec, label=\"test_accuracy\")\n",
    "    fig_plot.legend(loc=\"lower right\")\n",
    "    fig_plot.set_xlabel(\"epoch\")\n",
    "    fig_plot.set_ylabel(\"accuracy\")\n",
    "    fig_plot.grid(linestyle=\"--\")\n",
    "    fig.savefig(\"accuracy_plot.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from  ../data/fra-eng/fra.txt\n",
      "en_vocab 8293\n",
      "fr_vocab 13593\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "# reading data\n",
    "\n",
    "data = read_data(os.path.join(data_dir, \"fra-eng\"), \"fra.txt\")\n",
    "en_lines, fr_lines = list(zip(*data))\n",
    "en_lines_raw, fr_lines_raw = shuffle(en_lines, fr_lines)\n",
    "\n",
    "en_lines = en_lines_raw[:40000]\n",
    "fr_lines = fr_lines_raw[:40000]\n",
    "\n",
    "en_lines = [normalize(line) for line in en_lines]\n",
    "fr_lines = [normalize(line) for line in fr_lines]\n",
    "\n",
    "en_train, en_test, fr_train, fr_test = train_test_split(en_lines, fr_lines, shuffle=True, test_size=0.1)\n",
    "\n",
    "en_lines = en_test\n",
    "fr_lines = fr_test\n",
    "\n",
    "fr_train_in = ['<start> ' + line for line in fr_train]\n",
    "fr_train_out = [line + ' <end>' for line in fr_train]\n",
    "\n",
    "fr_test_in = ['<start> ' + line for line in fr_test]\n",
    "fr_test_out = [line + ' <end>' for line in fr_test]\n",
    "\n",
    "fr_tokenizer = Tokenizer(filters='')\n",
    "en_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "input_data = [fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train]\n",
    "fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train = tokenizeInput(input_data,\n",
    "                                                                                      fr_tokenizer)\n",
    "input_data = [en_train, en_test]\n",
    "en_train, en_test = tokenizeInput(input_data, en_tokenizer)\n",
    "\n",
    "en_vocab_size = len(en_tokenizer.word_index)+1\n",
    "fr_vocab_size = len(fr_tokenizer.word_index)+1\n",
    "print(\"en_vocab {}\\nfr_vocab {}\" .format(en_vocab_size, fr_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_TEXTS\n",
      "Do you need a few minutes?  -  As-tu besoin de quelques minutes ?\n",
      "I don't want to stay at home.  -  Je ne veux pas rester chez moi.\n",
      "I'm lucky to have you as a friend.  -  Je suis chanceuse de t'avoir pour ami.\n",
      "Do you give to charity?  -  Fais-tu la charité ?\n",
      "I had a phone call from him.  -  J'ai eu un appel téléphonique de sa part.\n",
      "At any rate, I hope you can come.  -  Quoi qu'il en soit, j'espère que tu pourras venir.\n",
      "Dinner's ready.  -  Le dîner est prêt.\n",
      "She has to look after her mother.  -  Il lui faut s'occuper de sa mère.\n",
      "It's not all that ridiculous.  -  Ce n'est pas si ridicule que cela.\n",
      "Can you say that again?  -  Pouvez-vous répéter cela ?\n"
     ]
    }
   ],
   "source": [
    "prediction_idx = np.random.randint(low=40000, high=len(en_lines_raw), size=10)\n",
    "print(\"TEST_TEXTS\")\n",
    "test_text = [(en_lines_raw[idx], fr_lines_raw[idx]) for idx in prediction_idx]\n",
    "for (en,fr) in test_text:\n",
    "    print(en, \" - \", fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIZE = 512\n",
    "EMBEDDING_SIZE = 256\n",
    "BATCH_SIZE= 64\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Seq2SeqPredictions():\n",
    "    trainer = Seq2SeqTrainer(BATCH_SIZE, LSTM_SIZE, EMBEDDING_SIZE, predict_every=10)\n",
    "    losses, accuracy = trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_lines, fr_lines], [en_tokenizer, fr_tokenizer], EPOCHS)\n",
    "    makePlots(losses, accuracy, \"Seq2Seq\")\n",
    "    for (en_text, fr_text) in test_text:\n",
    "        trainer.predict(en_text, fr_text)\n",
    "\n",
    "def Seq2SeqAttentionPredictions():\n",
    "    trainer = Seq2SeqAttentionTrainer(BATCH_SIZE, LSTM_SIZE, EMBEDDING_SIZE, predict_every=10)\n",
    "    losses, accuracy = trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_lines, fr_lines], [en_tokenizer, fr_tokenizer], EPOCHS, \"concat\")\n",
    "    makePlots(losses, accuracy, \"Seq2SeqAttention\")\n",
    "    for (en_text, fr_text) in test_text:\n",
    "        trainer.predict(en_text, fr_text, print_prediction=True)\n",
    "\n",
    "def TransformerPredictions():\n",
    "    BATCH_SIZE = 64\n",
    "    num_layers = 4 # 6\n",
    "    d_model = 256 # 512\n",
    "    dff = 512  # 2048\n",
    "    num_heads = 8\n",
    "    trainer = TransformerTrainer(BATCH_SIZE, num_layers, d_model, dff, num_heads, predict_every=10)\n",
    "    losses, accuracy= trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_tokenizer, fr_tokenizer], EPOCHS)\n",
    "    makePlots(losses, accuracy, \"Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab 8293\n",
      "fr_vocab 13593\n",
      "Number of devices: 4\n",
      "creating dataset...\n",
      "dataset created\n",
      "input :  What kind of music did you listen to when you were a teenager ?\n",
      "output:  Quelle sorte de musique ecoutais-tu lorsque tu etais adolescente ?\n",
      "training from scratch\n",
      "starting training with 1 epochs with prediction each 10 epoch\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1 training Loss 50.5177 Accuracy 0.0298  test Loss 43.9509 Accuracy 0.0698\n",
      "Saving checkpoint for epoch 0: ./checkpoints/Seq2Seq/ckpt-1\n",
      "--------------PREDICTION--------------\n",
      "  English   :  What kind of music did you listen to when you were a teenager ?\n",
      "  Predicted :  je ne ai pas pas pas pas de pas de .\n",
      "  Correct   :  Quelle sorte de musique ecoutais-tu lorsque tu etais adolescente ?\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  Do you need a few minutes?\n",
      "  Predicted :  je est .\n",
      "  Correct   :  As-tu besoin de quelques minutes ?\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  I don't want to stay at home.\n",
      "  Predicted :  je ne a pas .\n",
      "  Correct   :  Je ne veux pas rester chez moi.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  I'm lucky to have you as a friend.\n",
      "  Predicted :  je ne a pas .\n",
      "  Correct   :  Je suis chanceuse de t'avoir pour ami.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  Do you give to charity?\n",
      "  Predicted :  est .\n",
      "  Correct   :  Fais-tu la charité ?\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  I had a phone call from him.\n",
      "  Predicted :  je ne a pas .\n",
      "  Correct   :  J'ai eu un appel téléphonique de sa part.\n",
      "------------END PREDICTION------------\n",
      "--------------PREDICTION--------------\n",
      "  English   :  At any rate, I hope you can come.\n",
      "  Predicted :  je ne a pas .\n",
      "  Correct   :  Quoi qu'il en soit, j'espère que tu pourras venir.\n",
      "------------END PREDICTION------------\n"
     ]
    }
   ],
   "source": [
    "p = Process(target=Seq2SeqPredictions, args=())\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab 8293\n",
      "fr_vocab 13593\n",
      "Number of devices: 4\n",
      "creating dataset...\n",
      "dataset created\n",
      "input :  What kind of music did you listen to when you were a teenager ?\n",
      "output:  Quelle sorte de musique ecoutais-tu lorsque tu etais adolescente ?\n",
      "training from scratch\n",
      "starting training with 1 epochs with prediction each 10 epoch\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1 training Loss 0.8951 Accuracy 0.0238  test Loss 1.4117 Accuracy 0.0634\n",
      "Saving checkpoint for epoch 0: ./checkpoints/Seq2SeqAttention/ckpt-1\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence What kind of music did you listen to when you were a teenager ? \n",
      "       Predicted:  je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je \n",
      "       Should be:  Quelle sorte de musique ecoutais-tu lorsque tu etais adolescente ? \n",
      "--------------------------END PREDICTION--------------------------\n",
      "Saving checkpoint for end at ./checkpoints/Seq2SeqAttention/ckpt-2\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence Do you need a few minutes? \n",
      "       Predicted:  tom la a a a . \n",
      "       Should be:  As-tu besoin de quelques minutes ? \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence I don't want to stay at home. \n",
      "       Predicted:  je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je \n",
      "       Should be:  Je ne veux pas rester chez moi. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence I'm lucky to have you as a friend. \n",
      "       Predicted:  tom la . \n",
      "       Should be:  Je suis chanceuse de t'avoir pour ami. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence Do you give to charity? \n",
      "       Predicted:  tom nous est a a . \n",
      "       Should be:  Fais-tu la charité ? \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence I had a phone call from him. \n",
      "       Predicted:  je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je \n",
      "       Should be:  J'ai eu un appel téléphonique de sa part. \n",
      "--------------------------END PREDICTION--------------------------\n",
      "----------------------------PREDICTION----------------------------\n",
      "       En sentence At any rate, I hope you can come. \n",
      "       Predicted:  je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je je \n",
      "       Should be:  Quoi qu'il en soit, j'espère que tu pourras venir. \n",
      "--------------------------END PREDICTION--------------------------\n"
     ]
    }
   ],
   "source": [
    "p = Process(target=Seq2SeqAttentionPredictions, args=())\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab 8293\n",
      "fr_vocab 13593\n",
      "Number of devices: 4\n",
      "creating dataset...\n",
      "training from scratch\n",
      "INFO:tensorflow:batch_all_reduce: 170 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 170 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1 training Loss 81.4558 Accuracy 0.0129  test Loss 75.2164 Accuracy 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-7-436f1dfd4c3d>\", line 22, in TransformerPredictions\n",
      "    losses, accuracy= trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_tokenizer, fr_tokenizer], EPOCHS)\n",
      "  File \"../Transformer/TransformerTrainer.py\", line 206, in train\n",
      "    self.predict(en_test[idx], fr_test_out[idx])\n",
      "AttributeError: 'TransformerTrainer' object has no attribute 'predict'\n"
     ]
    }
   ],
   "source": [
    "p = Process(target=TransformerPredictions, args=())\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
