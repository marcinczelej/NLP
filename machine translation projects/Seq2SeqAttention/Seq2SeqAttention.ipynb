{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2SeqAttention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mizzmir/NLP/blob/master/machine%20translation%20projects/Seq2SeqAttention/Seq2SeqAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gt1BXkCOjge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow-gpu --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiWYjnc4P_0G",
        "colab_type": "code",
        "outputId": "b47e78ac-8a60-489b-c66c-daa8aafbfaa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/mizzmir/data.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHzn2juDOuKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import unicodedata\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwOBy64XO8A5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalize(s):\n",
        "    s = unicode_to_ascii(s)\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z.!?-]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s\n",
        "\n",
        "def read_data(data_dir, file_name):\n",
        "    full_path = os.path.join(data_dir, file_name)\n",
        "    print(\"reading data from \", full_path)\n",
        "\n",
        "    with open(full_path) as file:\n",
        "      lines = file.readlines()\n",
        "    \n",
        "    data = []\n",
        "\n",
        "    for line in lines:\n",
        "        data.append(line.split(\"\\t\")[:-1])\n",
        "    \n",
        "    return data\n",
        "\n",
        "def read_data_files(data_dir, file_names):\n",
        "    \n",
        "    en_file_name, fr_file_name = file_names\n",
        "    \n",
        "    full_path = os.path.join(data_dir, en_file_name)\n",
        "    print(\"reading data from \", full_path)\n",
        "\n",
        "    with open(full_path) as file:\n",
        "      en_lines = file.readlines()\n",
        "    \n",
        "    full_path = os.path.join(data_dir, fr_file_name)\n",
        "    print(\"reading data from \", full_path)\n",
        "\n",
        "    with open(full_path) as file:\n",
        "      fr_lines = file.readlines()    \n",
        "    \n",
        "    return en_lines, fr_lines\n",
        "\n",
        "def preprocessSeq(texts, tokenizer):\n",
        "  texts = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "  return pad_sequences(texts, padding='post')\n",
        "\n",
        "def tokenizeInput(input_data, tokenizer):\n",
        "    output_data = []\n",
        "    for data in input_data:\n",
        "        tokenizer.fit_on_texts(data)\n",
        "    \n",
        "    for data in input_data:\n",
        "        output_data.append(preprocessSeq(data, tokenizer))\n",
        "    \n",
        "    return output_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R_7ag1WPFDH",
        "colab_type": "code",
        "outputId": "2632cb1d-b122-486c-a93f-829769a09b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data_dir = \"/content/data\"\n",
        "\n",
        "# reading data\n",
        "#en_lines, fr_lines = read_data_files(data_dir, (\"small_vocab_en\", \"small_vocab_fr\"))\n",
        "\n",
        "data = read_data(data_dir, \"fra.txt\")\n",
        "en_lines, fr_lines = list(zip(*data))\n",
        "\n",
        "en_lines = en_lines[:40000]\n",
        "fr_lines = fr_lines[:40000]\n",
        "\n",
        "\n",
        "en_lines = [normalize(line) for line in en_lines]\n",
        "fr_lines = [normalize(line) for line in fr_lines]\n",
        "\n",
        "en_train, en_test, fr_train, fr_test = train_test_split(en_lines, fr_lines, shuffle=True, test_size=0.1)\n",
        "\n",
        "fr_train_in = ['<start> ' + line for line in fr_train]\n",
        "fr_train_out = [line + ' <end>' for line in fr_train]\n",
        "\n",
        "fr_test_in = ['<start> ' + line for line in fr_test]\n",
        "fr_test_out = [line + ' <end>' for line in fr_test]\n",
        "\n",
        "fr_tokenizer = Tokenizer(filters='')\n",
        "en_tokenizer = Tokenizer(filters='')\n",
        "\n",
        "input_data = [fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train]\n",
        "fr_train_in, fr_train_out, fr_test_in, fr_test_out, fr_test, fr_train = tokenizeInput(input_data,\n",
        "                                                                                      fr_tokenizer)\n",
        "\n",
        "input_data = [en_train, en_test]\n",
        "en_train, en_test = tokenizeInput(input_data, en_tokenizer)\n",
        "\n",
        "en_vocab_size = len(en_tokenizer.word_index)+1\n",
        "fr_vocab_size = len(fr_tokenizer.word_index)+1\n",
        "print(\"en_vocab {}\\nfr_vocab {}\" .format(en_vocab_size, fr_vocab_size))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading data from  /content/data/fra.txt\n",
            "en_vocab 5178\n",
            "fr_vocab 9851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXBrMgd2Qi_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Encoder Decoder\n",
        "#\n",
        "import tensorflow as tf\n",
        "\n",
        "\"\"\"\n",
        "class that implements LuangAttention\n",
        "  - uses current decoder output as input to calculate alligment vector\n",
        "  - score = h_t_trans*W_a*h_s\n",
        "  - h_t - decoder hideden_state\n",
        "  - h_s - encoder_output\n",
        "  - context_vector = softmax(score)\n",
        "\"\"\"\n",
        "class LuangAttention(tf.keras.Model):\n",
        "  def __init__(self, lstm_size, attention_type):\n",
        "    super(LuangAttention, self).__init__()\n",
        "\n",
        "    self.W_a = tf.keras.layers.Dense(lstm_size, name=\"LuangAttention_W_a\")\n",
        "    self.W_a_tanh = tf.keras.layers.Dense(lstm_size, activation=\"tanh\", name=\"LuangAttention_W_a_tanh\")\n",
        "    self.v_a = tf.keras.layers.Dense(1)\n",
        "    self.type = attention_type\n",
        "  \n",
        "  def call(self, decoder_output, encoder_output):\n",
        "    # encoder_output shape [batch_size, seq_max_len, hidden_units_of_encoder]\n",
        "    # decoder_output shape [batch_size, 1, hidden_units of decoder]\n",
        "    # score shape [batch_size, 1, seq_max_len]\n",
        "    if self.type == \"dot\":\n",
        "        score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
        "    elif self.type == \"general\":\n",
        "        score = tf.matmul(decoder_output, self.W_a(encoder_output), transpose_b=True)\n",
        "    elif self.type == \"concat\":\n",
        "        decoder_output = tf.broadcast_to(decoder_output, encoder_output.shape)\n",
        "        concated = self.W_a_tanh(tf.concat((decoder_output, encoder_output), axis=-1))\n",
        "        score = tf.transpose(self.v_a(concated), [0,2,1])\n",
        "    else:\n",
        "        raise Exception(\"wrong score function selected\")\n",
        "        \n",
        "    alignment_vector = tf.nn.softmax(score, axis=2)\n",
        "    context_vector = tf.matmul(alignment_vector, encoder_output)\n",
        "\n",
        "    return context_vector, alignment_vector\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, lstm_units, embedding_size, vocab_size):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.units = lstm_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size, name=\"Encoder_embedding\")\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(units=lstm_units, dropout=0.2, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "  def call(self, input_seq, initial_state):\n",
        "    # input_seq =shape [batch_size, seq_max_len]\n",
        "    # initial_state shape [batch_size, lstm_hidden_state_size]\n",
        "\n",
        "    # embedding shape [batch_size, seq_max_len, embedding_size]\n",
        "    embedded_input = self.embedding(input_seq)\n",
        "    #encoder output shape [batch_size, seq_max_len, lstm_size]\n",
        "    # state_h, state_c shape 2*[batch_size, lstm_size]\n",
        "    encoder_out, state_h, state_c = self.lstm_layer(inputs=embedded_input, initial_state=initial_state)\n",
        "\n",
        "    return encoder_out, state_h, state_c\n",
        "  \n",
        "  def init_states(self, batch_size):\n",
        "    return (tf.zeros([batch_size, self.units]),\n",
        "            tf.zeros([batch_size, self.units]))\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, lstm_units, embedding_size, vocab_size, attention_type):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.units = lstm_units\n",
        "    self.embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_size, name=\"Decoder_embedding\")\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(lstm_units, dropout=0.2, return_sequences=True, return_state=True, name=\"Decoder_lstm\")\n",
        "    self.dense_layer = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = LuangAttention(lstm_units, attention_type)\n",
        "\n",
        "    self.W_c = tf.keras.layers.Dense(lstm_units, activation=\"tanh\", name=\"Attention_W_c\")\n",
        "    self.W_s = tf.keras.layers.Dense(vocab_size, name=\"Attenton_W_s\")\n",
        "\n",
        "  def call(self, decoder_input, hidden_states, encoder_output):\n",
        "    # decoder_input shape [batch_size, 1]\n",
        "    # hidden_states shape 2*[batch_size, lstm_size]\n",
        "    # encoder_output shape [batch_size, seq_max_len, lstm_size]\n",
        "    embedded_input = self.embedding_layer(decoder_input)\n",
        "    # embedded_input shape [batch_size, 1, embedding_size]\n",
        "    # lstm_out shape [batch_size, 1, lstm_size]\n",
        "    # state_h, state_c shape 2*[batch_szie, lstm_size]\n",
        "    lstm_out, state_h, state_c = self.lstm_layer(embedded_input, hidden_states)\n",
        "\n",
        "    # context shape [batch_size, 1 lstm_size]\n",
        "    # alignment shape [batch_size, 1, source_len]\n",
        "    context, alignment = self.attention(lstm_out, encoder_output)\n",
        "\n",
        "    # lstm_out shape [batch_size, lstm_size + lstm_size]\n",
        "    lstm_out = tf.concat([tf.squeeze(context, axis=1), tf.squeeze(lstm_out, axis=1)], axis=1, name=\"Decoder_concat\")\n",
        "\n",
        "    # output_vector shape [batch_size, lstm_units]\n",
        "    output_vector = self.W_c(lstm_out)\n",
        "\n",
        "    # conversion to vocabulaty prob\n",
        "    # output_vector shape [batch_size, vocab_size]\n",
        "    output_vector = self.W_s(output_vector)\n",
        "    return output_vector, state_h, state_c, alignment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_ksVldRQ0z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_SIZE = 512\n",
        "EMBEDDING_SIZE = 250\n",
        "BATCH_SIZE= 64\n",
        "EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCCUpHkNQLCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqAttentionTrainer:\n",
        "    def __init__(self, batch_size, lstm_size, embedding_size, predict_every):\n",
        "        self.batch_size = batch_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.predict_every = predict_every\n",
        "        self.strategy = tf.distribute.MirroredStrategy()\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.optimizer = None\n",
        "        self.fr_tokenizer = None\n",
        "        self.en_tokenizer = None\n",
        "\n",
        "    def predict(self, en_sentence, fr_sentence):\n",
        "        real_en_sentence =' '.join([self.en_tokenizer.index_word[i] for i in en_sentence if i not in [0]]) \n",
        "        fr_sentence = ' '.join([self.fr_tokenizer.index_word[i] for i in fr_sentence if i not in [0]]) \n",
        "        en_sentence = tf.expand_dims(en_sentence, 0)\n",
        "        initial_states = self.encoder.init_states(1)\n",
        "        encoder_out, state_h, state_c = self.encoder(tf.constant(en_sentence), initial_states, training=False)\n",
        "\n",
        "        decoder_in = tf.constant([[self.fr_tokenizer.word_index['<start>']]])\n",
        "        sentence = []\n",
        "        alignments = []\n",
        "        while True:\n",
        "            decoder_out, state_h, state_c, alignment = self.decoder( \\\n",
        "                            decoder_in, (state_h, state_c), encoder_out, training=False)\n",
        "            # argmax to get max index \n",
        "            decoder_in = tf.expand_dims(tf.argmax(decoder_out, -1), 0)\n",
        "            word = self.fr_tokenizer.index_word[decoder_in.numpy()[0][0]]\n",
        "\n",
        "            alignments.append(alignment)\n",
        "\n",
        "            if  word == '<end>':\n",
        "                break\n",
        "            sentence.append(word)\n",
        "\n",
        "        predicted_sentence = ' '.join(sentence)\n",
        "        \n",
        "        print(\"----------------------------PREDICTION----------------------------\")\n",
        "        print(\"       En sentence {} \" .format(real_en_sentence))\n",
        "        print(\"       Predicted:  {} \" .format(predicted_sentence))\n",
        "        print(\"       Should be:  {} \" .format(fr_sentence))\n",
        "        print(\"--------------------------END PREDICTION--------------------------\")\n",
        "        \n",
        "        return np.array(alignments), real_en_sentence.split(' '), predicted_sentence.split(' ')\n",
        "\n",
        "    def train(self, train_dataset_data, test_dataset_data, tokenizers, epochs, attention_type, restore_checkpoint=True):\n",
        "        \"\"\"\n",
        "            train_dataset_data should be made from (en_train, fr_train_in, fr_train_out)\n",
        "            test_dataset_data should be made from (en_test, fr_test_in, fr_test_out)\n",
        "        \"\"\"\n",
        "        \n",
        "        print_heatmap=True\n",
        "        \n",
        "        self.en_tokenizer, self.fr_tokenizer = tokenizers\n",
        "        en_vocab_size = len(self.en_tokenizer.word_index)+1\n",
        "        fr_vocab_size = len(self.fr_tokenizer.word_index)+1\n",
        "        print(\"en_vocab {}\\nfr_vocab {}\" .format(en_vocab_size, fr_vocab_size))\n",
        "        \n",
        "        print ('Number of devices: {}'.format(self.strategy.num_replicas_in_sync))\n",
        "        GLOBAL_BATCH_SIZE = self.batch_size*self.strategy.num_replicas_in_sync\n",
        "\n",
        "        print(\"creating dataset...\")\n",
        "        en_train, fr_train_in, fr_train_out = train_dataset_data\n",
        "        en_test, fr_test_in, fr_test_out = test_dataset_data\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((en_train, fr_train_in, fr_train_out))\n",
        "        train_dataset = train_dataset.shuffle(len(en_train), reshuffle_each_iteration=True)\\\n",
        "                                        .batch(GLOBAL_BATCH_SIZE, drop_remainder=True)\n",
        "        train_dist_dataset = self.strategy.experimental_distribute_dataset(train_dataset)\n",
        "\n",
        "        test_dataset = tf.data.Dataset.from_tensor_slices((en_test, fr_test_out))\n",
        "        test_dataset = test_dataset.shuffle(len(en_test), reshuffle_each_iteration=True)\\\n",
        "                                       .batch(GLOBAL_BATCH_SIZE, drop_remainder=True)\n",
        "        test_dist_dataset = self.strategy.experimental_distribute_dataset(test_dataset)\n",
        "        print(\"dataset created\")\n",
        "        \n",
        "        test_losses = []\n",
        "        train_losses = []\n",
        "        train_accuracyVec = []\n",
        "        test_accuracyVec =[]\n",
        "        test_accuracy = tf.keras.metrics.Mean()\n",
        "        train_accuracy = tf.keras.metrics.Mean()\n",
        "        one_step_test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "        prediction_idx = np.random.randint(low=0, high=len(en_test), size=1)[0]\n",
        "        prediction_en, prediction_fr = en_test[prediction_idx], fr_test_out[prediction_idx]\n",
        "\n",
        "        if not os.path.exists(\"heatmap\"):\n",
        "          os.mkdir(\"heatmap\")\n",
        "\n",
        "        alignments = []\n",
        "\n",
        "        with self.strategy.scope():\n",
        "            self.encoder = Encoder(self.lstm_size, self.embedding_size, en_vocab_size)\n",
        "            self.decoder = Decoder(self.lstm_size, self.embedding_size, fr_vocab_size, attention_type)\n",
        "            self.optimizer = tf.keras.optimizers.Adam(clipnorm=0.5)\n",
        "            \n",
        "            ckpt = tf.train.Checkpoint(encoder=self.encoder,\n",
        "                                       decoder = self.decoder,\n",
        "                                       optimizer=self.optimizer,\n",
        "                                       epoch=tf.Variable(1))\n",
        "\n",
        "            manager = tf.train.CheckpointManager(ckpt, \"./checkpoints/Seq2SeqAttention\", max_to_keep=5)\n",
        "\n",
        "            \n",
        "            if manager.latest_checkpoint and restore_checkpoint:\n",
        "                ckpt.restore(manager.latest_checkpoint)\n",
        "                print ('Latest checkpoint restored!!')\n",
        "            else:\n",
        "                print(\"training from scratch\")\n",
        "\n",
        "            loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                        from_logits=True, reduction=\"none\")\n",
        "            def compute_loss(predictions, labels):\n",
        "                mask = tf.math.logical_not(tf.math.equal(labels, 0))\n",
        "                mask = tf.cast(mask, tf.int64)\n",
        "                per_example_loss = loss_obj(labels, predictions, sample_weight=mask)\n",
        "                return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "            \n",
        "            # one training step\n",
        "            def train_step(en_data, fr_data_in, fr_data_out, initial_states):\n",
        "                loss = 0\n",
        "                one_step_test_accuracy.reset_states()\n",
        "                with tf.GradientTape() as tape:\n",
        "                    encoder_output, state_h, state_c = self.encoder(en_data, initial_states, training=True)\n",
        "                    # shape[1] because we want each word for all batches\n",
        "                    for i in range(fr_data_out.shape[1]):\n",
        "                        decoder_input = tf.expand_dims(fr_data_in[:,i], 1)\n",
        "                        decoder_output, state_h, state_c, _ = self.decoder(decoder_input,\n",
        "                                                                        (state_h, state_c),\n",
        "                                                                        encoder_output,\n",
        "                                                                        training=True)\n",
        "                        loss +=compute_loss(decoder_output, fr_data_out[:,i])\n",
        "                        one_step_test_accuracy.update_state(decoder_output, fr_data_out[:,i])\n",
        "\n",
        "                trainable_vars = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "                grads = tape.gradient(loss, trainable_vars)\n",
        "                self.optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "\n",
        "                train_accuracy.update_state(one_step_test_accuracy.result())\n",
        "                return loss / fr_data_out.shape[1]\n",
        "\n",
        "            @tf.function\n",
        "            def distributed_train_step(en_data, fr_data_in, fr_data_out, initial_states):\n",
        "                per_replica_losses = self.strategy.experimental_run_v2(train_step,\n",
        "                                                                  args=(en_data,\n",
        "                                                                        fr_data_in,\n",
        "                                                                        fr_data_out,\n",
        "                                                                        initial_states,))\n",
        "                return self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "            def test_step(en_data, fr_data_out):\n",
        "                loss = 0\n",
        "                one_step_test_accuracy.reset_states()\n",
        "                initial_states = self.encoder.init_states(self.batch_size)\n",
        "                encoder_output, state_h, state_c = self.encoder(en_data, initial_states, training=False)\n",
        "\n",
        "                decoder_input = tf.constant(self.fr_tokenizer.word_index['<start>'], shape=(self.batch_size, 1))\n",
        "\n",
        "                for i in range(fr_data_out.shape[1]): \n",
        "                    decoder_output, state_h, state_c, _ = self.decoder(decoder_input,\n",
        "                                                                    (state_h, state_c),\n",
        "                                                                    encoder_output,\n",
        "                                                                    training=False)\n",
        "                    decoder_input =tf.expand_dims(tf.argmax(decoder_output, 1),1)\n",
        "                    loss +=compute_loss(decoder_output, fr_data_out[:,i])\n",
        "                    one_step_test_accuracy.update_state(decoder_output, fr_data_out[:,i])\n",
        "                \n",
        "                train_accuracy.update_state(one_step_test_accuracy.result())\n",
        "                return loss/fr_data_out.shape[1]\n",
        "\n",
        "            @tf.function\n",
        "            def distributed_test_step(en_data, fr_data_out):\n",
        "                per_replica_losses = self.strategy.experimental_run_v2(test_step,\n",
        "                                                                 args=(en_data,\n",
        "                                                                       fr_data_out,))\n",
        "                return self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "            print(\"starting training with {} epochs with prediction each {} epoch\" .format(epochs, self.predict_every))\n",
        "            for epoch in range(epochs):\n",
        "                test_accuracy.reset_states()\n",
        "                train_accuracy.reset_states()\n",
        "                initial_states = self.encoder.init_states(self.batch_size)\n",
        "                \n",
        "                total_loss = 0.0\n",
        "                num_batches = 0\n",
        "                for _, (en_data, fr_data_in, fr_data_out) in enumerate(train_dist_dataset):\n",
        "                    loss = distributed_train_step(en_data, fr_data_in, fr_data_out, initial_states)\n",
        "                    total_loss += loss\n",
        "                    num_batches += 1\n",
        "                train_losses.append(total_loss/num_batches)\n",
        "                total_loss = 0.0\n",
        "                num_batches = 0\n",
        "                for _, (en_data, fr_data_out) in enumerate(test_dist_dataset):\n",
        "                    loss = distributed_test_step(en_data, fr_data_out)\n",
        "                    total_loss += loss\n",
        "                    num_batches += 1\n",
        "                \n",
        "                test_losses.append(total_loss/num_batches)\n",
        "                print ('Epoch {} training Loss {:.4f} Accuracy {:.4f}  test Loss {:.4f} Accuracy {:.4f}' .format( \\\n",
        "                                                  epoch + 1, \n",
        "                                                  train_losses[-1], \n",
        "                                                  train_accuracy.result(),\n",
        "                                                  test_losses[-1],\n",
        "                                                  test_accuracy.result()))\n",
        "                \n",
        "                train_accuracyVec.append(train_accuracy.result())\n",
        "                test_accuracyVec.append(test_accuracy.result())\n",
        "                ckpt.epoch.assign_add(1)\n",
        "                if int(epoch) % 5 == 0:\n",
        "                    save_path = manager.save()\n",
        "                    print(\"Saving checkpoint for epoch {}: {}\".format(epoch, save_path))\n",
        "                if epoch % self.predict_every == 0:         \n",
        "                    alignment, source, predicted = self.predict(prediction_en, prediction_fr)\n",
        "                    attention_map = np.squeeze(alignment, (1, 2))\n",
        "                    alignments.append(attention_map)\n",
        "                    if print_heatmap:\n",
        "                        fig = plt.figure(figsize=(10, 10))\n",
        "                        ax = fig.add_subplot(1, 1, 1)\n",
        "                        ax.matshow(attention_map, cmap='jet')\n",
        "                        ax.set_xticklabels([''] + source, rotation=90)\n",
        "                        ax.set_yticklabels([''] + predicted[:-1])\n",
        "\n",
        "                        plt.savefig('heatmap/prediction_{}.png' .format(epoch//self.predict_every))\n",
        "                        plt.show()\n",
        "                        plt.close()\n",
        "            save_path = manager.save()\n",
        "            print ('Saving checkpoint for end at {}'.format(save_path))\n",
        "\n",
        "        return (train_losses, test_losses), (train_accuracyVec, test_accuracyVec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFijmdG7QoZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = Seq2SeqAttentionTrainer(BATCH_SIZE, LSTM_SIZE, EMBEDDING_SIZE, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l9fzFSvQ7dH",
        "colab_type": "code",
        "outputId": "734c9726-09e7-4983-aac4-221433ee654e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "losses, accuracy = trainer.train([en_train, fr_train_in, fr_train_out], [en_test, fr_test_in, fr_test_out], [en_tokenizer, fr_tokenizer], EPOCHS, \"concat\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en_vocab 5178\n",
            "fr_vocab 9851\n",
            "Number of devices: 1\n",
            "creating dataset...\n",
            "dataset created\n",
            "Latest checkpoint restored!!\n",
            "starting training with 20 epochs with prediction each 5 epoch\n",
            "Epoch 1 training Loss 1.0097 Accuracy 0.0000  test Loss 2.3639 Accuracy 0.0000\n",
            "Saving checkpoint for epoch 0: ./checkpoints/Seq2SeqAttention/ckpt-2\n",
            "----------------------------PREDICTION----------------------------\n",
            "       En sentence did i break it ? \n",
            "       Predicted:  l ai-je fait ? \n",
            "       Should be:  l ai-je brisee ? <end> \n",
            "--------------------------END PREDICTION--------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAGSCAYAAADQP9StAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAQPElEQVR4nO3df6xkd1nH8c9Tt/KjXVpbNopRutTw\nqyBBeo1FgVRsYpFABI0EjdoYXCqNmEIUJSTEaJQYqgE1wf1LCIRgQiWg8sMILZCCdEtNKZRAgoUI\nRLspmC0ghfD1jztLtruz7XL3Pvs9d/f1Sjadc87Mnaff3mbfOTNzpsYYAQBge501ewAAgNORyAIA\naCCyAAAaiCwAgAYiCwCggcgCAGggsgAAGogsAIAGIgu2qKoetGbfBTNmAWB5RBZs3fVVdfbhjap6\nRJJ/nTgPAAsismDr3pHkH6rq+6pqb5L3JvmjqRMBsBjluwth66rqmiRXJtmb5MVjjJvmTgTAUogs\n+B5V1cuO3EzyG0luS3Jrkowx/nLGXAAsy67ZA8AOtPuo7euPsx+AM5gzWQAADZzJgi2qqj1J/iDJ\nE5I8+PD+McYzpw0FwGL4dCFs3VuSfDrJo5L8cZI7k9w8cyAAlsPLhbBFVXXLGOPSqrptjPGk1b6b\nxxg/OXs2AObzciFs3bdW//xyVT07yZeSuOI7AElEFpyMP62q85K8PMlfJ3lYkmvnjgTAUni5EACg\ngTe+wxZV1WOq6t+q6vbV9pOq6lWz5wJgGZzJSlJV70py3IUYYzz3FI7DDlFVNyb5/SR/N8b4idW+\n28cYT5w7GQBL4D1Zm167+ufzk/xQkjevtl+Y5L+nTMRO8NAxxseq6sh93541DADLIrKSjDFuTJKq\num6MsXHEoXdV1YFJY7F8B6vqx7I6C1pVv5zky3NHAmApRNZ9nVNVF48xPpckVfWoJOdMnonluibJ\n/iSPq6ovJvnPJL82dyQAlkJk3de1SW6oqs8lqSQXJXnx3JFYoqo6K8nGGOOKqjonyVljjEOz5wJg\nObzx/ShV9aAkj1ttfnqM8c2Z87BcVXXgqJeXAeC7RFaSqnrmGOP9VfX8dcfHGNef6plYvqp6TZKD\nSd6W5GuH948x7p42FACL4eXCTc9I8v4kz8l9L+VQq22RxTovyObvx0uO2n/xhFkAWBiRtelQVb0s\nye3Z/Evz8Gfynebj/lySzcB6WjZ/Vz6U5A1TJ1qAqvq9McbrHmgfwOnOFd83nZtkd5JLk/xOkkck\n+eEkVyd5ysS5WLY3Jnl8ktdn87sLL1ntO9P95pp9V53qIZagqi6oqldW1cuq6mGz5wFOLe/JOkJV\nfTDJsw9/Sqyqdif55zHGM+ZOxhJV1afGGJc80L4zRVW9MMmvZvPM3oeOOLQ7yXfGGD83ZbCJquoD\nST6S5EFJrkzynMOXiAFOf14uvK8fTHLvEdv3rvbBOh+vqsvGGB9Nkqr6qSRn8sVrb8rmxVgfnuS6\nI/YfSnLblInmu3CM8cokqar3Jbmxqr6a5OVJXjTG+JWp0wGtRNZ9vSnJx6rqH1fbv5jk7+eNwxJV\n1Sey+R6ss5PcVFVfWG1flOTTM2ebaYzx+SSfT/LU2bMsyKGq2jvGuHOM8d6qemQ234rwlSSfmDwb\n0MzLhUepqqckefpq84NjjFtnzjNTVX14jPG0qjqUNZ+6HGOcke8xqaqL7u/4KjbOOH5fjlVVj83m\nv/tnZs8CnHoiCwCggU8XAgA0EFkAAA1E1v2oqn2zZ1gaa7KedVnPuqxnXY5lTdazLuvtlHURWfdv\nR/xHPMWsyXrWZT3rsp51OZY1Wc+6rLcj1kVkAQA0WNynC6vOH5vfarMEX01y/uwhVr4+e4CVe7L5\nLUTzff+ly5gjSb5z11dy1p4fmD1GkuSifGH2CN/1v3d9K+ftOXv2GEmSz96ylP+Xk+RrSc6ZPcTK\nUq63fFeSPbOHWLn3ge9yytyd5ILZQ6ws6dKaB7N53eMluPXgGGPtL++SVmzlEXH9z3U+PnuAxfmR\nA77taJ3X55rZIyzSs+q5s0dYqGtnD7BAX5w9wEItJfaW5pzjXhvRy4UAAA1EFgBAA5EFANBAZAEA\nNBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEA\nNBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEA\nNDilkVVV95zK5wMAmMWZLACABiILAKCByAIAaLCIyKqqfVV1oKoOJF+dPQ4AwElbRGSNMfaPMTbG\nGBvJ+bPHAQA4aYuILACA043IAgBocEoja4xx7ql8PgCAWZzJAgBoILIAABqILACABiILAKCByAIA\naCCyAAAaiCwAgAYiCwCggcgCAGggsgAAGogsAIAGIgsAoIHIAgBoILIAABqILACABiILAKCByAIA\naCCyAAAaiCwAgAYiCwCggcgCAGggsgAAGogsAIAGIgsAoIHIAgBoILIAABqILACABiILAKCByAIA\naCCyAAAa7Jo9wNEuuPQb+fkDn5w9xuK8tZ4ye4TF+dy/P2H2CIv0rNtvmD3CQr1t9gAL9Y3ZAyzQ\nHbMHWKhvzx5gx3EmCwCggcgCAGggsgAAGogsAIAGIgsAoIHIAgBoILIAABqILACABiILAKCByAIA\naCCyAAAaiCwAgAYiCwCggcgCAGggsgAAGogsAIAGIgsAoIHIAgBoILIAABqILACABiILAKCByAIA\naCCyAAAaiCwAgAYiCwCggcgCAGggsgAAGogsAIAGIgsAoIHIAgBosOXIqqp/qarz1+x/blX94cmN\nBQCws+3a6gPHGL9wnP3vTPLOLU8EAHAaOKEzWVX1jqq6pao+WVX7VvvurKqHr7nvVVX1N6vbe6rq\n7VV18+rPz2zv+AAAy3SiZ7J+a4xxd1U9JMnNVfX2E3zc65L81Rjjw1X1yCTvTfL4rQwKALCTnGhk\nvbSqnre6/aNJHn2Cj7siySVVdXj7YVV17hjjniPvtDo7ti9JHvrIC0/wRwMALNcDRlZVXZ7NWHrq\nGOPrVXVDkgcfcfyaJL+92jz6fVpnJblsjPF/9/ccY4z9SfYnyYUbe8eJDg8AsFQn8p6s85J8ZRVY\nj0ty2ZEHxxh/O8Z48urPl4567PuS/O7hjap68klPDACwA5xIZL0nya6quiPJa5J89AQec/hs1EuT\nbFTVbVX1qSRXb21MAICd5QFfLhxjfDPJs9Yc2nuch1yY5O7VYw8mecFWhwMA2Km2fJ2sdarq6iRX\nJXn+dv5cAICdZlu/VmeM8YYxxo+PMT67nT8XAGCn8d2FAAANRBYAQAORBQDQQGQBADQQWQAADUQW\nAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQW\nAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQYNfsAY529y0jb61v\nzh5jgT4+e4DFGb9+2ewRFunyz7x79giLdOOL7pg9wkJZl2OdPXuAhdo9e4Adx5ksAIAGIgsAoIHI\nAgBoILIAABqILACABiILAKCByAIAaCCyAAAaiCwAgAYiCwCggcgCAGggsgAAGogsAIAGIgsAoIHI\nAgBoILIAABqILACABiILAKCByAIAaCCyAAAaiCwAgAYiCwCggcgCAGggsgAAGogsAIAGIgsAoIHI\nAgBoILIAABqILACABiILAKCByAIAaLDlyKqql1bVHVX1luMc36iq169uX15VP73V5wIA2Gl2ncRj\nX5LkijHGf607OMY4kOTAavPyJPckuekkng8AYMfY0pmsqnpDkouTvLuqXlFVH6mqW6vqpqp67Oo+\nl1fVP1XV3iRXJ7m2qv6jqp6+XcMDACzVls5kjTGurqork/xsknuTXDfG+HZVXZHkz5L80hH3vXMV\nZfeMMV67HUMDACzdybxceNh5Sd5YVY9OMpKc/b3+gKral2Tf5tYF2zASAMBc2/Hpwj9J8oExxhOT\nPCfJg7/XHzDG2D/G2BhjbCTnbsNIAABzbUdknZfki6vbVx3nPoeS7N6G5wIA2BG2I7L+IsmfV9Wt\nOf7Lj+9K8jxvfAcAzhRbfk/WGGPv6ubBJI854tCrVsdvSHLD6vZnkjxpq88FALDTuOI7AEADkQUA\n0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA\n0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA\n0EBkAQA0EFkAAA1EFgBAg12zBzjWWUkeMnuIBbImR6tXjNkjLNKrq2aPsEg35tWzR2DHWOBfjYtw\naPYAO44zWQAADUQWAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQ\nQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQ\nQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQ\nYNfsAZKkqvYl2be5deHUWQAAtsMizmSNMfaPMTbGGBvJ7tnjAACctEVEFgDA6UZkAQA0EFkAAA1E\nFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1E\nFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1E\nFgBAA5EFANBAZAEANBBZAAANRBYAQINdswc41oVJrpo9xALdMnuA5Xnz7AGW6bp7/mf2CMv0mj2z\nJ1im98weYIEOzB5gqT41e4CFetVxjziTBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1E\nFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1E\nFgBAA5EFANBAZAEANBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1E\nFgBAA5EFANBAZAEANFhEZFXVvqo6UFUHkrtmjwMAcNIWEVljjP1jjI0xxkayZ/Y4AAAnbRGRBQBw\nuhFZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEA\nNBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0EFkAAA1EFgBAA5EFANBAZAEA\nNBBZAAANRBYAQAORBQDQQGQBADQQWQAADUQWAEADkQUA0EBkAQA0qDHG7Bnuo6ruSvL52XOsPDzJ\nwdlDLIw1Wc+6rGdd1rMux7Im61mX9Za0LheNMfasO7C4yFqSqjowxtiYPceSWJP1rMt61mU963Is\na7KedVlvp6yLlwsBABqILACABiLr/u2fPcACWZP1rMt61mU963Isa7KedVlvR6yL92QBADRwJgsA\noIHIAgBoILIAABqILACABiILAKDB/wNj44aUNgLl+gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 training Loss 0.6606 Accuracy 0.0000  test Loss 2.0524 Accuracy 0.0000\n",
            "Epoch 3 training Loss 0.4557 Accuracy 0.0000  test Loss 2.0156 Accuracy 0.0000\n",
            "Epoch 4 training Loss 0.3388 Accuracy 0.0000  test Loss 1.9940 Accuracy 0.0000\n",
            "Epoch 5 training Loss 0.2677 Accuracy 0.0000  test Loss 2.0516 Accuracy 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiD8-8tHRI92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses, test_losses = losses \n",
        "train_accuracyVec, test_accuracyVec = accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlhT--W5RKTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "fig_plot = fig.add_subplot()\n",
        "fig_plot.plot(train_losses, label=\"train_loss\")\n",
        "fig_plot.plot(test_losses, label=\"test_loss\")\n",
        "fig_plot.legend(loc=\"upper right\")\n",
        "fig_plot.set_xlabel(\"epoch\")\n",
        "fig_plot.set_ylabel(\"loss\")\n",
        "fig_plot.grid(linestyle=\"--\")\n",
        "fig.savefig(\"losses_plot.png\")\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl6Fh-poRMOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "fig_plot = fig.add_subplot()\n",
        "fig_plot.plot(train_accuracyVec, label=\"train_accuracy\")\n",
        "fig_plot.plot(test_accuracyVec, label=\"test_accuracy\")\n",
        "fig_plot.legend(loc=\"lower right\")\n",
        "fig_plot.set_xlabel(\"epoch\")\n",
        "fig_plot.set_ylabel(\"accuracy\")\n",
        "fig_plot.grid(linestyle=\"--\")\n",
        "fig.savefig(\"accuracy_plot.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}