{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sys.path.insert(0, r\"../utilities\")\n",
    "\n",
    "from utils import *\n",
    "from params import *\n",
    "from Seq2SeqAttentionTrainer import Seq2SeqAttentionTrainer\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from  ../data/small_vocab_en\n",
      "reading data from  ../data/small_vocab_fr\n",
      "en_tokenizer size  542\n",
      "fr_tokenizer size  709\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data\"\n",
    "en_lines, fr_lines = read_data_files(data_dir, (\"small_vocab_en\", \"small_vocab_fr\"))\n",
    "\n",
    "#data = read_data(os.path.join(data_dir, \"fra-eng\"), \"fra.txt\")\n",
    "\n",
    "#en_lines, fr_lines = list(zip(*data))\n",
    "#en_lines, fr_lines = shuffle(en_lines, fr_lines)\n",
    "\n",
    "#en_lines = en_lines[:30000]\n",
    "#fr_lines = fr_lines[:30000]\n",
    "\n",
    "en_lines = [normalize(line) for line in en_lines]\n",
    "fr_lines = [normalize(line) for line in fr_lines]\n",
    "\n",
    "en_train, en_test, fr_train, fr_test = train_test_split(en_lines, fr_lines, shuffle=True, test_size=0.1)\n",
    "\n",
    "en_lines = en_test\n",
    "fr_lines = fr_test\n",
    "\n",
    "# creating tokenizers\n",
    "en_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en for en in en_train), target_vocab_size=2**13)\n",
    "\n",
    "fr_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (fr for fr in fr_train), target_vocab_size=2**13)\n",
    "\n",
    "print(\"en_tokenizer size \", en_tokenizer.vocab_size)\n",
    "print(\"fr_tokenizer size \", fr_tokenizer.vocab_size)\n",
    "\n",
    "# train dataset\n",
    "fr_train_in = [[fr_tokenizer.vocab_size] + fr_tokenizer.encode(line) for line in fr_train]\n",
    "fr_train_out = [fr_tokenizer.encode(line) + [fr_tokenizer.vocab_size+1] for line in fr_train]\n",
    "\n",
    "fr_train_in = pad_sequences(fr_train_in, padding='post')\n",
    "fr_train_out = pad_sequences(fr_train_out, padding='post')\n",
    "\n",
    "# test dataset\n",
    "fr_test_in = [[fr_tokenizer.vocab_size] + fr_tokenizer.encode(line) for line in fr_test]\n",
    "fr_test_out = [fr_tokenizer.encode(line) + [fr_tokenizer.vocab_size+1] for line in fr_test]\n",
    "\n",
    "fr_test_in = pad_sequences(fr_test_in, padding='post')\n",
    "fr_test_out = pad_sequences(fr_test_out, padding='post')\n",
    "\n",
    "en_train = [en_tokenizer.encode(line) for line in en_train]\n",
    "en_test = [en_tokenizer.encode(line) for line in en_test]\n",
    "\n",
    "en_train = pad_sequences(en_train, padding='post')\n",
    "en_test = pad_sequences(en_test, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqAttentionTrainer(batch_size=BATCH_SIZE, \n",
    "                                  lstm_size=LSTM_SIZE, \n",
    "                                  embedding_size=EMBEDDING_SIZE, \n",
    "                                  tokenizers=[en_tokenizer, fr_tokenizer],\n",
    "                                  predict_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4\n",
      "creating dataset...\n",
      "prediction input :  california is usually snowy during october but it is relaxing in august . \n",
      "prediction output:  californie est generalement enneigee en octobre mais il est relaxant au mois d aout . \n",
      "training from scratch\n",
      "starting training with 20 epochs with prediction each 5 epoch\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Efficient allreduce is not supported for 2 IndexedSlices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training Loss 0.8785 Accuracy 0.3888  test Loss 0.4425 Accuracy 0.4556\n",
      "Saving checkpoint for epoch 0: ./checkpoints/Seq2SeqAttention/ckpt-1\n",
      "----------------------------PREDICTION----------------------------\n",
      "Predicted:  [<tf.Tensor: id=300839, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[2.7673268e-01, 2.4809645e-01, 1.7862366e-01, 1.2725733e-01,\n",
      "         8.8961758e-02, 5.9171915e-02, 1.4649533e-02, 4.9717911e-03,\n",
      "         1.0557234e-03, 2.8343583e-04, 1.0302673e-04, 5.7459558e-05,\n",
      "         3.5213037e-05]]], dtype=float32)>, <tf.Tensor: id=301018, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.10927676, 0.11739983, 0.12743676, 0.12478688, 0.11346258,\n",
      "         0.10429692, 0.07168653, 0.06264309, 0.04893987, 0.04122101,\n",
      "         0.03262901, 0.02578465, 0.02043615]]], dtype=float32)>, <tf.Tensor: id=301197, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[2.8182485e-04, 2.9419368e-04, 3.3036666e-04, 3.4846086e-04,\n",
      "         3.4604076e-04, 3.5897130e-04, 4.0688185e-04, 5.9199042e-04,\n",
      "         1.2122691e-03, 4.7294800e-03, 3.5024334e-02, 1.9237016e-01,\n",
      "         7.6370502e-01]]], dtype=float32)>, <tf.Tensor: id=301376, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.00100094, 0.00106316, 0.00126758, 0.00138733, 0.0014023 ,\n",
      "         0.00148641, 0.00170485, 0.00259813, 0.00566024, 0.02203692,\n",
      "         0.11139581, 0.30929396, 0.53970236]]], dtype=float32)>, <tf.Tensor: id=301555, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.05800201, 0.06016281, 0.07370944, 0.08222212, 0.08862016,\n",
      "         0.10163929, 0.07329039, 0.0908118 , 0.09696455, 0.10870476,\n",
      "         0.08705785, 0.05296255, 0.02585226]]], dtype=float32)>, <tf.Tensor: id=301734, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.12060429, 0.11560436, 0.11999521, 0.12145159, 0.12680838,\n",
      "         0.13929361, 0.06733943, 0.06394755, 0.04576969, 0.03709034,\n",
      "         0.02380174, 0.01338796, 0.00490587]]], dtype=float32)>, <tf.Tensor: id=301913, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.01698951, 0.01786832, 0.02229252, 0.0252426 , 0.02685875,\n",
      "         0.03059754, 0.02771952, 0.03916254, 0.05948149, 0.11539304,\n",
      "         0.19314778, 0.22248304, 0.2027633 ]]], dtype=float32)>, <tf.Tensor: id=302092, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.11107843, 0.11456019, 0.12708367, 0.12904426, 0.1239328 ,\n",
      "         0.12412652, 0.07550607, 0.06917445, 0.05045888, 0.03680798,\n",
      "         0.02084002, 0.01156218, 0.00582464]]], dtype=float32)>, <tf.Tensor: id=302271, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.00402849, 0.0043644 , 0.0054433 , 0.0061163 , 0.00630496,\n",
      "         0.00684721, 0.00793374, 0.01181709, 0.02251804, 0.06451674,\n",
      "         0.20040554, 0.31805438, 0.34164977]]], dtype=float32)>, <tf.Tensor: id=302450, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.00091912, 0.00096577, 0.00106856, 0.00111098, 0.00107905,\n",
      "         0.00108413, 0.00117957, 0.00149686, 0.00250074, 0.00715071,\n",
      "         0.04032864, 0.19582944, 0.74528635]]], dtype=float32)>, <tf.Tensor: id=302629, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.00240137, 0.00259644, 0.00320293, 0.00361369, 0.00382426,\n",
      "         0.00425474, 0.00536205, 0.00846441, 0.01776566, 0.05555424,\n",
      "         0.18298762, 0.32915732, 0.38081524]]], dtype=float32)>, <tf.Tensor: id=302808, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[0.0639398 , 0.06716742, 0.07885148, 0.08529644, 0.09036257,\n",
      "         0.10000993, 0.07542262, 0.08879716, 0.09421075, 0.1024014 ,\n",
      "         0.08018255, 0.04871505, 0.02464281]]], dtype=float32)>, <tf.Tensor: id=302987, shape=(1, 1, 13), dtype=float32, numpy=\n",
      "array([[[2.3002210e-01, 2.1950337e-01, 1.7349215e-01, 1.3583332e-01,\n",
      "         1.0790423e-01, 8.2944527e-02, 2.7076403e-02, 1.3783982e-02,\n",
      "         5.3146291e-03, 2.3960520e-03, 1.0120692e-03, 4.9139984e-04,\n",
      "         2.2573402e-04]]], dtype=float32)>] \n",
      "Should be:  californie est generalement enneigee en octobre mais il est relaxant au mois d aout .  \n",
      "--------------------------END PREDICTION--------------------------\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m         \u001b[0msqueeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'squeeze'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e1aadb06122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 \u001b[0mprediction_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0men_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_lines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                 attention_type=\"concat\")\n\u001b[0m",
      "\u001b[0;32m/shared/NLP/machine translation projects/Seq2SeqAttention/Seq2SeqAttentionTrainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, test_data, prediction_data, epochs, attention_type, restore_checkpoint)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprint_heatmap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                     \u001b[0mattention_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                     \u001b[0malignments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0msqueeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'squeeze'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "losses, accuracy= trainer.train(train_data=[en_train, fr_train_in, fr_train_out], \n",
    "                                test_data=[en_test, fr_test_in, fr_test_out], \n",
    "                                prediction_data=[en_lines, fr_lines], \n",
    "                                epochs=20, \n",
    "                                attention_type=\"concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig_plot = fig.add_subplot()\n",
    "fig_plot.plot(train_losses, label=\"train_loss\")\n",
    "fig_plot.plot(test_losses, label=\"test_loss\")\n",
    "fig_plot.legend(loc=\"upper right\")\n",
    "fig_plot.set_xlabel(\"epoch\")\n",
    "fig_plot.set_ylabel(\"loss\")\n",
    "fig_plot.grid(linestyle=\"--\")\n",
    "fig.savefig(\"losses_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig_plot = fig.add_subplot()\n",
    "fig_plot.plot(train_accuracyVec, label=\"train_accuracy\")\n",
    "fig_plot.plot(test_accuracyVec, label=\"test_accuracy\")\n",
    "fig_plot.legend(loc=\"lower right\")\n",
    "fig_plot.set_xlabel(\"epoch\")\n",
    "fig_plot.set_ylabel(\"accuracy\")\n",
    "fig_plot.grid(linestyle=\"--\")\n",
    "fig.savefig(\"accuracy_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.translate(\"What are you doing?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
