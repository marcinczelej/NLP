{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2SeqAttentionColab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mizzmir/NLP/blob/machine_translation_develop/machine%20translation%20projects/Seq2SeqAttention/Seq2SeqAttentionColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4gt1BXkCOjge",
        "colab": {}
      },
      "source": [
        "pip install tensorflow-gpu --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GiWYjnc4P_0G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3dd8b78-de68-40c9-d0df-0ac0b6867fab"
      },
      "source": [
        "!git clone https://github.com/mizzmir/data.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gHzn2juDOuKo",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import unicodedata\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DwOBy64XO8A5",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalize(s):\n",
        "    s = unicode_to_ascii(s)\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z.!?-]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s\n",
        "\n",
        "def read_data(data_dir, file_name):\n",
        "    full_path = os.path.join(data_dir, file_name)\n",
        "    print(\"reading data from \", full_path)\n",
        "\n",
        "    with open(full_path) as file:\n",
        "      lines = file.readlines()\n",
        "    \n",
        "    data = []\n",
        "\n",
        "    for line in lines:\n",
        "        data.append(line.split(\"\\t\")[:-1])\n",
        "    \n",
        "    return data\n",
        "\n",
        "def read_data_files(data_dir, file_names):\n",
        "    \n",
        "    en_file_name, fr_file_name = file_names\n",
        "    \n",
        "    full_path = os.path.join(data_dir, en_file_name)\n",
        "    print(\"reading data from \", full_path)\n",
        "\n",
        "    with open(full_path) as file:\n",
        "      en_lines = file.readlines()\n",
        "    \n",
        "    full_path = os.path.join(data_dir, fr_file_name)\n",
        "    print(\"reading data from \", full_path)\n",
        "\n",
        "    with open(full_path) as file:\n",
        "      fr_lines = file.readlines()    \n",
        "    \n",
        "    return en_lines, fr_lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6R_7ag1WPFDH",
        "outputId": "fc96ca07-0c45-4203-f1cc-01033583b88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_dir = \"/content/data\"\n",
        "en_lines, fr_lines = read_data_files(data_dir, (\"small_vocab_en\", \"small_vocab_fr\"))\n",
        "\n",
        "#data = read_data(os.path.join(data_dir, \"fra-eng\"), \"fra.txt\")\n",
        "\n",
        "#en_lines, fr_lines = list(zip(*data))\n",
        "en_lines, fr_lines = shuffle(en_lines, fr_lines)\n",
        "\n",
        "#en_lines = en_lines[:40000]\n",
        "#fr_lines = fr_lines[:40000]\n",
        "\n",
        "en_lines = [normalize(line) for line in en_lines]\n",
        "fr_lines = [normalize(line) for line in fr_lines]\n",
        "\n",
        "en_train, en_test, fr_train, fr_test = train_test_split(en_lines, fr_lines, shuffle=True, test_size=0.1)\n",
        "\n",
        "en_lines = en_test\n",
        "fr_lines = fr_test\n",
        "\n",
        "# creating tokenizers\n",
        "en_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (en for en in en_train), target_vocab_size=2**13)\n",
        "\n",
        "fr_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (fr for fr in fr_train), target_vocab_size=2**13)\n",
        "\n",
        "print(\"en_tokenizer size \", en_tokenizer.vocab_size)\n",
        "print(\"fr_tokenizer size \", fr_tokenizer.vocab_size)\n",
        "\n",
        "en_tokenizer.save_to_file(\"en_tokenizer\")\n",
        "fr_tokenizer.save_to_file(\"fr_tokenizer\")\n",
        "\n",
        "# train dataset\n",
        "fr_train_in = [[fr_tokenizer.vocab_size] + fr_tokenizer.encode(line) for line in fr_train]\n",
        "fr_train_out = [fr_tokenizer.encode(line) + [fr_tokenizer.vocab_size+1] for line in fr_train]\n",
        "\n",
        "fr_train_in = pad_sequences(fr_train_in, padding='post')\n",
        "fr_train_out = pad_sequences(fr_train_out, padding='post')\n",
        "\n",
        "# test dataset\n",
        "fr_test_in = [[fr_tokenizer.vocab_size] + fr_tokenizer.encode(line) for line in fr_test]\n",
        "fr_test_out = [fr_tokenizer.encode(line) + [fr_tokenizer.vocab_size+1] for line in fr_test]\n",
        "\n",
        "fr_test_in = pad_sequences(fr_test_in, padding='post')\n",
        "fr_test_out = pad_sequences(fr_test_out, padding='post')\n",
        "\n",
        "en_train = [en_tokenizer.encode(line) for line in en_train]\n",
        "en_test = [en_tokenizer.encode(line) for line in en_test]\n",
        "\n",
        "en_train = pad_sequences(en_train, padding='post')\n",
        "en_test = pad_sequences(en_test, padding='post')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading data from  /content/data/small_vocab_en\n",
            "reading data from  /content/data/small_vocab_fr\n",
            "en_tokenizer size  542\n",
            "fr_tokenizer size  710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cXBrMgd2Qi_m",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Encoder Decoder\n",
        "#\n",
        "\"\"\"\n",
        "class that implements LuangAttention\n",
        "  - uses current decoder output as input to calculate alligment vector\n",
        "  - score = h_t_trans*W_a*h_s\n",
        "  - h_t - decoder hideden_state\n",
        "  - h_s - encoder_output\n",
        "  - context_vector = softmax(score)\n",
        "\"\"\"\n",
        "class LuangAttention(tf.keras.Model):\n",
        "  def __init__(self, lstm_size, attention_type):\n",
        "    super(LuangAttention, self).__init__()\n",
        "\n",
        "    self.W_a = tf.keras.layers.Dense(lstm_size, name=\"LuangAttention_W_a\")\n",
        "    self.W_a_tanh = tf.keras.layers.Dense(lstm_size, activation=\"tanh\", name=\"LuangAttention_W_a_tanh\")\n",
        "    self.v_a = tf.keras.layers.Dense(1)\n",
        "    self.type = attention_type\n",
        "  \n",
        "  def call(self, decoder_output, encoder_output):\n",
        "    # encoder_output shape [batch_size, seq_max_len, hidden_units_of_encoder]\n",
        "    # decoder_output shape [batch_size, 1, hidden_units of decoder]\n",
        "    # score shape [batch_size, 1, seq_max_len]\n",
        "    if self.type == \"dot\":\n",
        "        score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
        "    elif self.type == \"general\":\n",
        "        score = tf.matmul(decoder_output, self.W_a(encoder_output), transpose_b=True)\n",
        "    elif self.type == \"concat\":\n",
        "        decoder_output = tf.broadcast_to(decoder_output, encoder_output.shape)\n",
        "        concated = self.W_a_tanh(tf.concat((decoder_output, encoder_output), axis=-1))\n",
        "        score = tf.transpose(self.v_a(concated), [0,2,1])\n",
        "    else:\n",
        "        raise Exception(\"wrong score function selected\")\n",
        "        \n",
        "    alignment_vector = tf.nn.softmax(score, axis=2)\n",
        "    context_vector = tf.matmul(alignment_vector, encoder_output)\n",
        "\n",
        "    return context_vector, alignment_vector\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, lstm_units, embedding_size, vocab_size):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.units = lstm_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size, name=\"Encoder_embedding\")\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(units=lstm_units, dropout=0.2, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "  def call(self, input_seq, initial_state, training_mode):\n",
        "    # input_seq =shape [batch_size, seq_max_len]\n",
        "    # initial_state shape [batch_size, lstm_hidden_state_size]\n",
        "\n",
        "    # embedding shape [batch_size, seq_max_len, embedding_size]\n",
        "    embedded_input = self.embedding(input_seq, training=training_mode)\n",
        "    #encoder output shape [batch_size, seq_max_len, lstm_size]\n",
        "    # state_h, state_c shape 2*[batch_size, lstm_size]\n",
        "    encoder_out, state_h, state_c = self.lstm_layer(inputs=embedded_input, initial_state=initial_state, training=training_mode)\n",
        "\n",
        "    return encoder_out, state_h, state_c\n",
        "  \n",
        "  def init_states(self, batch_size):\n",
        "    return (tf.zeros([batch_size, self.units]),\n",
        "            tf.zeros([batch_size, self.units]))\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, lstm_units, embedding_size, vocab_size, attention_type):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.units = lstm_units\n",
        "    self.embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_size, name=\"Decoder_embedding\")\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(lstm_units, dropout=0.2, return_sequences=True, return_state=True, name=\"Decoder_lstm\")\n",
        "    self.dense_layer = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = LuangAttention(lstm_units, attention_type)\n",
        "\n",
        "    self.W_c = tf.keras.layers.Dense(lstm_units, activation=\"tanh\", name=\"Attention_W_c\")\n",
        "    self.W_s = tf.keras.layers.Dense(vocab_size, name=\"Attenton_W_s\")\n",
        "\n",
        "  def call(self, decoder_input, hidden_states, encoder_output, training_mode):\n",
        "    # decoder_input shape [batch_size, 1]\n",
        "    # hidden_states shape 2*[batch_size, lstm_size]\n",
        "    # encoder_output shape [batch_size, seq_max_len, lstm_size]\n",
        "    embedded_input = self.embedding_layer(decoder_input, training=training_mode)\n",
        "    # embedded_input shape [batch_size, 1, embedding_size]\n",
        "    # lstm_out shape [batch_size, 1, lstm_size]\n",
        "    # state_h, state_c shape 2*[batch_szie, lstm_size]\n",
        "    lstm_out, state_h, state_c = self.lstm_layer(embedded_input, hidden_states, training=training_mode)\n",
        "\n",
        "    # context shape [batch_size, 1 lstm_size]\n",
        "    # alignment shape [batch_size, 1, source_len]\n",
        "    context, alignment = self.attention(lstm_out, encoder_output)\n",
        "\n",
        "    # lstm_out shape [batch_size, lstm_size + lstm_size]\n",
        "    lstm_out = tf.concat([tf.squeeze(context, axis=1), tf.squeeze(lstm_out, axis=1)], axis=1, name=\"Decoder_concat\")\n",
        "\n",
        "    # output_vector shape [batch_size, lstm_units]\n",
        "    output_vector = self.W_c(lstm_out)\n",
        "\n",
        "    # conversion to vocabulary prob\n",
        "    # output_vector shape [batch_size, vocab_size]\n",
        "    output_vector = self.W_s(output_vector)\n",
        "    return output_vector, state_h, state_c, alignment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfPRYjd64Zpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeDatasets(train_data, test_data, batch_size, strategy=None):\n",
        "        \"\"\"\n",
        "            Parameters:\n",
        "                train_data - input data for training. Should be in form : en_train, fr_train_in, fr_train_out\n",
        "                test_data - input data for test step. Should be in form : en_test, fr_test_in, fr_test_out\n",
        "                batch_size - batch_size that should be used to create datasets\n",
        "                strategy - strategy that datasets should use to be distributed across GPUs. Default is None\n",
        "        \"\"\"\n",
        "        print(\"creating dataset...\")\n",
        "        en_train, fr_train_in, fr_train_out = train_data\n",
        "        en_test, fr_test_in, fr_test_out = test_data\n",
        "        \n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((en_train, fr_train_in, fr_train_out))\n",
        "        train_dataset = train_dataset.shuffle(len(en_train), reshuffle_each_iteration=True)\\\n",
        "                                         .batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        test_dataset = tf.data.Dataset.from_tensor_slices((en_test, fr_test_in, fr_test_out))\n",
        "        test_dataset = test_dataset.shuffle(len(en_test), reshuffle_each_iteration=True)\\\n",
        "                                       .batch(batch_size, drop_remainder=True)\n",
        "        \n",
        "        if strategy is not None:\n",
        "            train_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "            test_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
        "        \n",
        "        return train_dataset, test_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aCCUpHkNQLCG",
        "colab": {}
      },
      "source": [
        "class Seq2SeqAttentionTrainer:\n",
        "    def __init__(self, batch_size, lstm_size, embedding_size, tokenizers, predict_every):\n",
        "        \"\"\"\n",
        "            Parameters: \n",
        "                batch_size - batch_size of input data,\n",
        "                lstm_size - number of lstm units\n",
        "                embedding_size - embedding size for wholde model    \n",
        "                tokenizers - two tokenizers for input and output data. Should be in form en_tokenizer, fr_tokenizer\n",
        "                predict_every - how often to write prediction during training\n",
        "        \"\"\"\n",
        "        \n",
        "        self.en_tokenizer, self.fr_tokenizer = tokenizers\n",
        "        self.batch_size = batch_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.predict_every = predict_every\n",
        "        self.strategy = tf.distribute.MirroredStrategy()\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.optimizer = None\n",
        "\n",
        "    def translate(self, en_sentence):\n",
        "        \"\"\"\n",
        "            Translates sentence\n",
        "            \n",
        "            Parameters:\n",
        "                en_sentence - sentence that will be translated\n",
        "            \n",
        "            returns:\n",
        "                translated sentence\n",
        "                alingments matrix - attention matrix for given translation\n",
        "        \"\"\"\n",
        "        tokenized_input_data = self.en_tokenizer.encode(en_sentence)      \n",
        "        tokenized_input_data = tf.expand_dims(tokenized_input_data, 0)\n",
        "        initial_states = self.encoder.init_states(1)\n",
        "        encoder_out, state_h, state_c = self.encoder(tf.constant(tokenized_input_data), \n",
        "                                                     initial_states, \n",
        "                                                     training_mode=False)\n",
        "\n",
        "        decoder_in = [self.fr_tokenizer.vocab_size]\n",
        "        decoder_in = tf.expand_dims(decoder_in, 0)\n",
        "        end_tag = self.fr_tokenizer.vocab_size+1\n",
        "        output_seq = []\n",
        "        alignments = []\n",
        "        while True:\n",
        "            decoder_out, state_h, state_c, alignment = self.decoder(decoder_in, \n",
        "                                                                    (state_h, state_c), \n",
        "                                                                    encoder_out, \n",
        "                                                                    training_mode=False)\n",
        "            # argmax to get max index \n",
        "            decoder_in = tf.expand_dims(tf.argmax(decoder_out, -1), 0)\n",
        "            predicted_data = decoder_in\n",
        "\n",
        "            if  predicted_data.numpy()[0] == end_tag or len(output_seq) >=40:\n",
        "                break\n",
        "             \n",
        "            alignments.append(alignment)\n",
        "            output_seq.append(self.fr_tokenizer.decode(predicted_data.numpy()[0]))\n",
        "            \n",
        "        return \"\".join(output_seq), alignments\n",
        "\n",
        "    def train(self, train_data, test_data, prediction_data, epochs, attention_type=\"general\", restore_checkpoint=False):\n",
        "        \"\"\"\n",
        "            Training method that uses distributed training\n",
        "            \n",
        "            Parameters:\n",
        "                train_data - input data for training. Should be in form : en_train, fr_train_in, fr_train_out\n",
        "                test_data - input data for test step. Should be in form : en_test, fr_test_in, fr_test_out\n",
        "                prediction_data - input data for prediction step. Should be in form of: en_predict, fr_predict\n",
        "                epochs - number of epochs that should be run\n",
        "                attention_type - what attention method to use \" dot/general/concat. Default - general\n",
        "                restore_checkpoint - should we restore last checkpoint and resume training. Defualt set to false.\n",
        "            \n",
        "            retuns:\n",
        "                tuple losses, accuracy where losses = (train_losses, test_losses), accuracy = (train-accuracy, test_accuracy)\n",
        "        \"\"\"\n",
        "        \n",
        "        print_heatmap=True\n",
        "        \n",
        "        en_predict, fr_predict = prediction_data\n",
        "        en_vocab_size = self.en_tokenizer.vocab_size\n",
        "        fr_vocab_size = self.fr_tokenizer.vocab_size + 2\n",
        "        \n",
        "        print ('Number of devices: {}'.format(self.strategy.num_replicas_in_sync))\n",
        "        GLOBAL_BATCH_SIZE = self.batch_size*self.strategy.num_replicas_in_sync\n",
        "\n",
        "        train_dataset_distr, test_dataset_distr = makeDatasets(train_data, test_data, GLOBAL_BATCH_SIZE, self.strategy)\n",
        "        \n",
        "        test_losses = []\n",
        "        train_losses = []\n",
        "        train_accuracyVec = []\n",
        "        test_accuracyVec =[]\n",
        "        test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "        prediction_idx = np.random.randint(low=0, high=len(en_predict), size=1)[0]\n",
        "        prediction_en, prediction_fr = en_predict[prediction_idx], fr_predict[prediction_idx]\n",
        "        print(\"prediction input : \", prediction_en)\n",
        "        print(\"prediction output: \", prediction_fr)\n",
        "\n",
        "        if not os.path.exists(\"heatmap\"):\n",
        "          os.mkdir(\"heatmap\")\n",
        "\n",
        "        alignments = []\n",
        "\n",
        "        with self.strategy.scope():\n",
        "            self.encoder = Encoder(lstm_units=self.lstm_size, \n",
        "                                   embedding_size=self.embedding_size, \n",
        "                                   vocab_size=en_vocab_size)\n",
        "            \n",
        "            self.decoder = Decoder(lstm_units=self.lstm_size, \n",
        "                                   embedding_size=self.embedding_size, \n",
        "                                   vocab_size=fr_vocab_size, \n",
        "                                   attention_type=attention_type)\n",
        "            \n",
        "            self.optimizer = tf.keras.optimizers.Adam(clipnorm=0.5)\n",
        "            \n",
        "            ckpt = tf.train.Checkpoint(encoder=self.encoder,\n",
        "                                       decoder = self.decoder,\n",
        "                                       optimizer=self.optimizer,\n",
        "                                       epoch=tf.Variable(1))\n",
        "\n",
        "            manager = tf.train.CheckpointManager(ckpt, \"./checkpoints/Seq2SeqAttention\", max_to_keep=5)\n",
        "\n",
        "            \n",
        "            if manager.latest_checkpoint and restore_checkpoint:\n",
        "                ckpt.restore(manager.latest_checkpoint)\n",
        "                print ('Latest checkpoint restored!!')\n",
        "            else:\n",
        "                print(\"training from scratch\")\n",
        "\n",
        "            loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                        from_logits=True, reduction=\"none\")\n",
        "            \n",
        "            def compute_loss(predictions, labels):\n",
        "                mask = tf.math.logical_not(tf.math.equal(labels, 0))\n",
        "                mask = tf.cast(mask, tf.int64)\n",
        "                per_example_loss = loss_obj(labels, predictions, sample_weight=mask)\n",
        "                return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "            \n",
        "            # one training step\n",
        "            def train_step(en_data, fr_data_in, fr_data_out, initial_states):\n",
        "                loss = 0\n",
        "                predicted_output = None\n",
        "                train_accuracy.reset_states()\n",
        "                with tf.GradientTape() as tape:\n",
        "                    encoder_output, state_h, state_c = self.encoder(en_data, \n",
        "                                                                    initial_states, \n",
        "                                                                    training_mode=True)\n",
        "                    # shape[1] because we want each word for all batches\n",
        "                    for i in range(fr_data_out.shape[1]):\n",
        "                        decoder_input = tf.expand_dims(fr_data_in[:,i], 1)\n",
        "                        decoder_output, state_h, state_c, _ = self.decoder(decoder_input,\n",
        "                                                                           (state_h, state_c),\n",
        "                                                                           encoder_output,\n",
        "                                                                           training_mode=True)\n",
        "                        \n",
        "                        loss +=compute_loss(decoder_output, fr_data_out[:,i])\n",
        "                        decoder_output = tf.expand_dims(decoder_output, axis=1)\n",
        "                        if i == 0:\n",
        "                          predicted_output = decoder_output\n",
        "                        else:\n",
        "                          predicted_output = tf.concat([predicted_output, decoder_output], axis=1)\n",
        "\n",
        "                trainable_vars = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "                grads = tape.gradient(loss, trainable_vars)\n",
        "                self.optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "\n",
        "                train_accuracy.update_state(fr_data_out, predicted_output)\n",
        "\n",
        "                return loss / fr_data_out.shape[1]\n",
        "\n",
        "            @tf.function\n",
        "            def distributed_train_step(en_data, fr_data_in, fr_data_out, initial_states):\n",
        "                per_replica_losses = self.strategy.experimental_run_v2(train_step,\n",
        "                                                                  args=(en_data,\n",
        "                                                                        fr_data_in,\n",
        "                                                                        fr_data_out,\n",
        "                                                                        initial_states,))\n",
        "                return self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "            def test_step(en_data, fr_data_in, fr_data_out):\n",
        "                loss = 0\n",
        "                predicted_output = []\n",
        "                initial_states = self.encoder.init_states(self.batch_size)\n",
        "                encoder_output, state_h, state_c = self.encoder(en_data, \n",
        "                                                                initial_states, \n",
        "                                                                training_mode=False)\n",
        "                for i in range(fr_data_out.shape[1]):\n",
        "                    decoder_input = tf.expand_dims(fr_data_in[:,i], 1)\n",
        "                    decoder_output, state_h, state_c, _ = self.decoder(decoder_input,\n",
        "                                                                    (state_h, state_c),\n",
        "                                                                    encoder_output,\n",
        "                                                                    training_mode=False)\n",
        "                    loss +=compute_loss(decoder_output, fr_data_out[:,i])\n",
        "\n",
        "                    decoder_output = tf.expand_dims(decoder_output, axis=1)\n",
        "                    if i == 0:\n",
        "                      predicted_output = decoder_output\n",
        "                    else:\n",
        "                      predicted_output = tf.concat([predicted_output, decoder_output], axis=1)\n",
        "                      \n",
        "                test_accuracy.update_state(fr_data_out, predicted_output)\n",
        "\n",
        "                return loss/fr_data_out.shape[1]\n",
        "\n",
        "            @tf.function\n",
        "            def distributed_test_step(en_data, fr_data_in, fr_data_out):\n",
        "                per_replica_losses = self.strategy.experimental_run_v2(test_step,\n",
        "                                                                 args=(en_data,\n",
        "                                                                       fr_data_in,\n",
        "                                                                       fr_data_out,))\n",
        "                return self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "            print(\"starting training with {} epochs with prediction each {} epoch\" .format(epochs, self.predict_every))\n",
        "            for epoch in range(epochs):\n",
        "                test_accuracy.reset_states()\n",
        "                train_accuracy.reset_states()\n",
        "                initial_states = self.encoder.init_states(self.batch_size)\n",
        "                \n",
        "                total_loss = 0.0\n",
        "                num_batches = 0\n",
        "                for _, (en_data, fr_data_in, fr_data_out) in enumerate(train_dataset_distr):\n",
        "                    loss = distributed_train_step(en_data, fr_data_in, fr_data_out, initial_states)\n",
        "                    total_loss += loss\n",
        "                    num_batches += 1\n",
        "                train_losses.append(total_loss/num_batches)\n",
        "                total_loss = 0.0\n",
        "                num_batches = 0\n",
        "                for _, (en_data, fr_data_in, fr_data_out) in enumerate(test_dataset_distr):\n",
        "                    loss = distributed_test_step(en_data, fr_data_in, fr_data_out)\n",
        "                    total_loss += loss\n",
        "                    num_batches += 1\n",
        "                \n",
        "                test_losses.append(total_loss/num_batches)\n",
        "                print ('Epoch {} training Loss {:.4f} Accuracy {:.4f}  test Loss {:.4f} Accuracy {:.4f}' .format( \\\n",
        "                                                  epoch + 1, \n",
        "                                                  train_losses[-1], \n",
        "                                                  train_accuracy.result(),\n",
        "                                                  test_losses[-1],\n",
        "                                                  test_accuracy.result()))\n",
        "                \n",
        "                train_accuracyVec.append(train_accuracy.result())\n",
        "                test_accuracyVec.append(test_accuracy.result())\n",
        "                ckpt.epoch.assign_add(1)\n",
        "\n",
        "                if int(epoch) % 5 == 0:\n",
        "                    save_path = manager.save()\n",
        "                    print(\"Saving checkpoint for epoch {}: {}\".format(epoch, save_path))\n",
        "\n",
        "                predicted, alignment  = self.translate(prediction_en)\n",
        "                \n",
        "                if epoch % self.predict_every == 0:\n",
        "                    print(\"----------------------------PREDICTION----------------------------\")\n",
        "                    print(\"Predicted:  {} \" .format(predicted))\n",
        "                    print(\"Should be:  {} \" .format(prediction_fr))\n",
        "                    print(\"--------------------------END PREDICTION--------------------------\")\n",
        "                    \n",
        "                if print_heatmap:\n",
        "                    attention_map = np.squeeze(alignment, (1, 2))\n",
        "                    alignments.append(attention_map)\n",
        "                    fig = plt.figure(figsize=(10, 10))\n",
        "                    ax = fig.add_subplot(1, 1, 1)\n",
        "                    ax.matshow(attention_map, cmap='jet')\n",
        "                    ax.set_xticklabels([''] + prediction_en.split(' '), rotation=90)\n",
        "                    ax.set_yticklabels([''] + predicted.split(' '))\n",
        "\n",
        "                    plt.savefig('heatmap/prediction_{}.png' .format(epoch))\n",
        "                    #plt.show()\n",
        "                    plt.close()\n",
        "            save_path = manager.save()\n",
        "            print ('Saving checkpoint for end at {}'.format(save_path))\n",
        "\n",
        "        return (train_losses, test_losses), (train_accuracyVec, test_accuracyVec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_ksVldRQ0z-",
        "colab": {}
      },
      "source": [
        "LSTM_SIZE = 512\n",
        "EMBEDDING_SIZE = 250\n",
        "BATCH_SIZE= 64\n",
        "EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lFijmdG7QoZX",
        "colab": {}
      },
      "source": [
        "trainer = Seq2SeqAttentionTrainer(batch_size=BATCH_SIZE, \n",
        "                                  lstm_size=LSTM_SIZE, \n",
        "                                  embedding_size=EMBEDDING_SIZE, \n",
        "                                  tokenizers=[en_tokenizer, fr_tokenizer],\n",
        "                                  predict_every=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9l9fzFSvQ7dH",
        "outputId": "9290baa5-dcc6-41c6-b16d-736daa54f5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "losses, accuracy= trainer.train(train_data=[en_train, fr_train_in, fr_train_out], \n",
        "                                test_data=[en_test, fr_test_in, fr_test_out], \n",
        "                                prediction_data=[en_lines, fr_lines], \n",
        "                                epochs=EPOCHS, \n",
        "                                attention_type=\"concat\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n",
            "creating dataset...\n",
            "prediction input :  he likes pears grapefruit and oranges . \n",
            "prediction output:  il aime les poires les pamplemousses et les oranges . \n",
            "training from scratch\n",
            "starting training with 20 epochs with prediction each 2 epoch\n",
            "Epoch 1 training Loss 0.4361 Accuracy 0.4732  test Loss 0.0678 Accuracy 0.6123\n",
            "Saving checkpoint for epoch 0: ./checkpoints/Seq2SeqAttention/ckpt-1\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  jersey est pluvieux pluvieux juin mais les fraise est son verts .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 2 training Loss 0.0366 Accuracy 0.5975  test Loss 0.0242 Accuracy 0.6268\n",
            "Epoch 3 training Loss 0.0203 Accuracy 0.6029  test Loss 0.0180 Accuracy 0.6292\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  california est froid pendant juin et il est generalement pluvieux en octobre .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 4 training Loss 0.0154 Accuracy 0.6045  test Loss 0.0153 Accuracy 0.6301\n",
            "Epoch 5 training Loss 0.0122 Accuracy 0.6057  test Loss 0.0166 Accuracy 0.6299\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  california est froid pendant l ete et il est generalement froid en octobre .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 6 training Loss 0.0104 Accuracy 0.6063  test Loss 0.0128 Accuracy 0.6311\n",
            "Saving checkpoint for epoch 5: ./checkpoints/Seq2SeqAttention/ckpt-2\n",
            "Epoch 7 training Loss 0.0090 Accuracy 0.6067  test Loss 0.0107 Accuracy 0.6318\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  il est froid pendant l ete et il est generalement pluvieux en octobre .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 8 training Loss 0.0081 Accuracy 0.6070  test Loss 0.0115 Accuracy 0.6317\n",
            "Epoch 9 training Loss 0.0070 Accuracy 0.6074  test Loss 0.0115 Accuracy 0.6318\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  il est les poires et il est verts .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 10 training Loss 0.0066 Accuracy 0.6075  test Loss 0.0100 Accuracy 0.6322\n",
            "Epoch 11 training Loss 0.0058 Accuracy 0.6078  test Loss 0.0102 Accuracy 0.6321\n",
            "Saving checkpoint for epoch 10: ./checkpoints/Seq2SeqAttention/ckpt-3\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  il est les poires les pamplemousses et les oranges .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 12 training Loss 0.0053 Accuracy 0.6080  test Loss 0.0111 Accuracy 0.6321\n",
            "Epoch 13 training Loss 0.0051 Accuracy 0.6080  test Loss 0.0107 Accuracy 0.6323\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  il aime les poires les pamplemousses et les oranges .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 14 training Loss 0.0045 Accuracy 0.6082  test Loss 0.0103 Accuracy 0.6325\n",
            "Epoch 15 training Loss 0.0043 Accuracy 0.6083  test Loss 0.0106 Accuracy 0.6325\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  il aime les poires les pamplemousses et les oranges .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 16 training Loss 0.0041 Accuracy 0.6083  test Loss 0.0111 Accuracy 0.6325\n",
            "Saving checkpoint for epoch 15: ./checkpoints/Seq2SeqAttention/ckpt-4\n",
            "Epoch 17 training Loss 0.0040 Accuracy 0.6084  test Loss 0.0112 Accuracy 0.6324\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  il aime les poires les pamplemousses et les oranges .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 18 training Loss 0.0036 Accuracy 0.6085  test Loss 0.0106 Accuracy 0.6325\n",
            "Epoch 19 training Loss 0.0035 Accuracy 0.6085  test Loss 0.0111 Accuracy 0.6326\n",
            "----------------------------PREDICTION----------------------------\n",
            "Predicted:  l etats-unis les poires et les oranges .  \n",
            "Should be:  il aime les poires les pamplemousses et les oranges .  \n",
            "--------------------------END PREDICTION--------------------------\n",
            "Epoch 20 training Loss 0.0035 Accuracy 0.6085  test Loss 0.0105 Accuracy 0.6326\n",
            "Saving checkpoint for end at ./checkpoints/Seq2SeqAttention/ckpt-5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BiD8-8tHRI92",
        "colab": {}
      },
      "source": [
        "train_losses, test_losses = losses \n",
        "train_accuracyVec, test_accuracyVec = accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QlhT--W5RKTp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "27978bf5-7da8-42e1-bc30-94a8f379b75c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "fig_plot = fig.add_subplot()\n",
        "fig_plot.plot(train_losses, label=\"train_loss\")\n",
        "fig_plot.plot(test_losses, label=\"test_loss\")\n",
        "fig_plot.legend(loc=\"upper right\")\n",
        "fig_plot.set_xlabel(\"epoch\")\n",
        "fig_plot.set_ylabel(\"loss\")\n",
        "fig_plot.grid(linestyle=\"--\")\n",
        "fig.savefig(\"losses_plot.png\")\n",
        "fig.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0UCgKIriczQQKIqi+Jz/Hy2kc3DCEJ+9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dl6Fh-poRMOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "88d44cdd-95af-4ae1-97de-e08145014fbd"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig_plot = fig.add_subplot()\n",
        "fig_plot.plot(train_accuracyVec, label=\"train_accuracy\")\n",
        "fig_plot.plot(test_accuracyVec, label=\"test_accuracy\")\n",
        "fig_plot.legend(loc=\"lower right\")\n",
        "fig_plot.set_xlabel(\"epoch\")\n",
        "fig_plot.set_ylabel(\"accuracy\")\n",
        "fig_plot.grid(linestyle=\"--\")\n",
        "fig.savefig(\"accuracy_plot.png\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMrcgNhZmZF/wWXVO6uvFrq/AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}